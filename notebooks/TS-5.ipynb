{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional networks : case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we summarize some of the main innovations of recent Convolutional Neural Network (CNN) architectures. These case studies can serve as inspiration for coming up with new ideas to apply to this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet Classification with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![http://benanne.github.io/images/imagenet.png](http://benanne.github.io/images/imagenet.png)\n",
    "\n",
    "This paper presents the winning system n the classification task of the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) 2012 competition. The system is a Deep Convolutional Neural Network, trained at the time on 2 NVIDIA GTX-580 GPU's for 6 days.\n",
    "\n",
    "An interesting aspect of the paper is that, beyond just presenting the details of the CNN (AlexNet), it tries to discover which of the techniques used was essential for performance and which of them only offered relatively minor gains. The most important characteristic is proibably the depth of the CNN's; removing any of the middle layers has been shown to lead in approximately 2% top-1 performance loss. \n",
    "\n",
    "Also essential are the use of Dropout and of image augmentation (by extracting 224x224 patches out of 256x256 images and doing horizontal reflections), especially because they help with preventing overfitting. The use of Rectified Linear Units (ReLUs) also helped speed up training and somewhat lessen the vanishing gradient problem. On the other hand, the use of Local Response Normalization, overlapping pooling and two column organization (to help with code parallelization on the 2 GPU's) don't seem as important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfeat: integrated recognition, localization and detection'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This paper presents the winning system in the classification task of the ILSVRC 2013 competition. The innovations compared to the 2012 winning system are that no contrast normalization is used, the pooling regions are non-overlapping and smaller strides are used for the first 2 convolutional layers. Also, multiple scales and 1x1 convolutions instead of fully-connected layers are used; 1x1 convolution filters can be used to deal with images of varying resolution (the output of the CNN becomes a matrix, which can, for example, be averaged for the final classification prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Deep Convolutional Networks for Large Scale Image Recognition (VGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This paper presents the system which secured the first place in the localization task and the second place in the classification task at ILSVRC 2014.\n",
    "Compared to the two systems described above, this CNN (VGGNet) is much deeper (16-19 weight layers compared to 7 for AlexNet). It also replaces convolutional layers with large receptive fields (e.g. 7x7) with series of convolutional layers with small 3x3 receptive fields. \n",
    "\n",
    "This leads to more expressiveness (because of stacked nonlinearities replacing single ones) with less parameters and computation. The overall architecture is also more uniform and thus simpler, using 3x3 receptive fields with stride 1 (which preserve spatial resolution), 1x1 receptive fields and, respectively. 2x2 max-pooling with stride 2. The number of convolutional layers (channels) consists of powers of 2 and increases by a factor of 2 after each max-pooling; this further simplifies the network design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going deeper with convolutions (Googlenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The CNN presented in this paper has won the ILSRVC 2014 classification and detections tasks. It uses 'Inception' modules inspired from theoretical work which has shown that if the probability distribution of a dataset is representable by a large, very sparse, deep neural network, then the optimal network topology can be constructed layer by layer by analyzing the correlation statistics of the activations of the last layer and clustering neurons with highly correlated outputs'. The entire architecture is judiciously designed to approximate how an optimal local sparse structure can be approximated using dense CNN components, which work well with the caches and architectures of modern computational platforms which make heavy use of parallelization (such as GPUs). \n",
    "\n",
    "The resulting CNN is very deep; to facilitate training and alleviate the vanishing gradient problem, auxiliary classifier layers are added on top of middle convolutional layers, and their losses discounted and added to the main loss during training. During inference, these additional classifier layers are removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Striving for simplicity: the all convolutional net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The authors experiment with replacing max-pooling for dimensionality reduction with convolutional layers with stride 2, with the purpose of simplifying CNN architectures. They obtain state of the art performances on the CIFAR-10 and CIFAR-100 datasets, highlighting the case that the use of pooling is not strictly necessary for good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying plankton with deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This section covers a blog post which describes the winning solution of The National Data Science Bowl, a data science competition where the goal was to classify images of plankton. Given the similarity of that competition to this challenge, we could expect to gather some helpful insights.  \n",
    "\n",
    "As preprocessing, only global zero mean unit variance normalization has been performed. For data augmentation, various affine transforms has been used (rotation, translation, rescaling, flipping, shearing, stretching). The images have been rescaled so that their larger side has fixed length. \n",
    "\n",
    "The network architecture was highly inspired by the VGG architecture presented earlier, using convolutional layers with 3x3 receptive fields and 3x3 max-pooling with stride 2 and depths up to 16 layers. Leaky ReLUs were used as nonlinearities. \n",
    "Unsupervised pretraining with contractive auto-encoders has been used; an alternative for reducing training time could be starting from a model pretrained on ImageNet (perhaps even the VGGNet).\n",
    "\n",
    "For optimization, stochastic gradient descent (SGD) with Nesterov momentum was used. \n",
    "\n",
    "An interesting characteristic of the specific task was that the size of the organisms in the images did not depend on the distance to the lens of the camera, such that the image size carries useful information for classifying the species. The authors took advantage of this characteristic by combining the predictions of a network with input rescaled based on image size with those of a network with inputs rescaled by a fixed factor ('multiscale' architecture). \n",
    "\n",
    "An innovation used by the winning solution was cyclic pooling (concatenating the features of images rotated at 0, 90, 180 and 270 degreees which are extracted by the same network, and then performing root mean-square pooling across those 4 feature maps). This can also be extended to cyclic rolling, where each of the 4 feature maps from different orientations are combined into a big stack and the next layer of feature maps is learned starting from this representation.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
