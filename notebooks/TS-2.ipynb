{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "from utils import plot_decision_boundary\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](nn.png)\n",
    "\n",
    "**Reference**  http://www.rsipvision.com/exploring-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With neural networks, units are organized in layers, you can think of each **layer** as a representation of the inputs, just like we did with polynomials, except that these representations are learned from data. \n",
    "\n",
    "In this view, the **input layer** and the **output layer** are no longer special layers, but also representations of the same data.\n",
    "\n",
    "- The **input layer** are the raw representation of the data\n",
    "- The **output layer** can also be seen as a representation of the same data, except that it is a very abstract representation (for instance, class labels)\n",
    "- **Hidden layers** are representations of intermediate levels of abstraction going from less abstract to more abstract as we go from the input layer to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In feedforward neural networks, each layer is a linear transformation of the previous layer for which we apply a non-linear function called the **activation function**. Or put it in another way, each unit of each layer is a linear combination of all the units of the previous layer for which we apply a non-linear function called the **activation function**.\n",
    "\n",
    "A feedforward neural network can thus be easily expressed using products of matrices, for instance let's say we have 2 hidden layers.\n",
    "\n",
    "let's say $x$ is an input vector:\n",
    "\n",
    "- $h_1 = g^{(1)}(W^{(1)}x + b^{(1)})$ is the first hidden layer\n",
    "- $h_2 = g^{(2)}(W^{(2)} h_1 + b^{(2)})$ is the second hidden layer\n",
    "- $y = g^{(3)}(W^{(3)}h_2 + b^{(3)})$ is the output layer\n",
    "\n",
    "where:\n",
    "\n",
    "- $g^{(l)}$ is the activation function of the layer l\n",
    "- $W^{(l)}$ are called the weights and they determine the linear transformation we use from one layer to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's build a simple example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((500, 2), (500, 100), (500, 50), (500, 1))\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.uniform(0, 1, size=(X.shape[1], 100)) # 100 units in the first layer\n",
    "W2 = np.random.uniform(0, 1, size=(100, 50)) # 50 units in the second layer\n",
    "W3 = np.random.uniform(0, 1, size=(50, 1)) # 1 unit in the output layer\n",
    "\n",
    "b1= np.random.uniform(0, 1, size=(100,))\n",
    "b2 = np.random.uniform(0, 1, size=(50))\n",
    "b3 = np.random.uniform(0, 1, size=(1,))\n",
    "\n",
    "g = np.tanh # the activation function is the same for all the layers\n",
    "\n",
    "h1 = g(np.dot(X, W1) + b1)\n",
    "h2 = g(np.dot(h1, W2) + b2)\n",
    "y = g(np.dot(h2, W3) + b3)\n",
    "\n",
    "print(X.shape, h1.shape, h2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a **task** and a **dataset**, for instance class prediction of insects, how do we train a neural network ?\n",
    "\n",
    "First, we specify what we want from the model through the **loss function**, also known as **objective function**.\n",
    "Usually it describes the difference between what what we predict and the \"truth\" and we want thus to minimize the **loss function**.\n",
    "\n",
    "For class prediction, the loss function could be the number of misclassifications on the training data.\n",
    "The problem with this loss function is that it is not smooth, and neural networks need smooth loss functions\n",
    "to be trained. We rather employ surrogates of the misclassification loss function and monitor the\n",
    "real loss function we want to minimize in training/valid/test data.\n",
    "\n",
    "For binary classification, the simplest loss function we can use is the mean squared error :\n",
    "\n",
    "$$L(X, y) = \\frac{1}{2N}\\sum_{i=1}^N (f(X_i) - y_i)^2$$\n",
    "\n",
    "where f is a function that computes the output of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the dataset and having defined the loss function, how do we \n",
    "actually train the weights of the neural network ?\n",
    "\n",
    "The usual algorithm for training neural networks is gradient descent (and its variants), which requires\n",
    "us to compute the derivatives of the loss function with respect to the parameters of the neural network, which\n",
    "are the weights and the biases.\n",
    "\n",
    "**Backpropagation** is an algorithm for computing the partial derivatives  of the loss function with respect\n",
    "to the parameters of any network defined by a Directed Acyclic Graph (DAG), it is basically\n",
    "a recursive application of the chain rule starting from the outputs and going backwards through\n",
    "the edges of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bp](backprop.png)\n",
    "\n",
    "Let's take a simple example. the above graph is a computation graph, each node is a function\n",
    "of its predecessors, the direction is the way we procede to compute the outputs, so\n",
    "we start at **r** and **t**, compute **x** based on **r** and **t**, compute **y** based on **r** and **t** then finally\n",
    "compute **u** based on **x** and **y**.\n",
    "\n",
    "The chain rule for partial derivatives tells us that :\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial r} = \\frac{\\partial u}{\\partial x}\\frac{\\partial x}{\\partial r} + \\frac{\\partial u}{\\partial y}\\frac{\\partial y}{\\partial r}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} = \\frac{\\partial u}{\\partial x}\\frac{\\partial x}{\\partial t} + \\frac{\\partial u}{\\partial y}\\frac{\\partial y}{\\partial t}$$\n",
    "\n",
    "and\n",
    "\n",
    "we have the expressions of $$\\frac{\\partial u}{\\partial x}$$ and\n",
    "$$\\frac{\\partial u}{\\partial y}$$  because they are direct predecessors of **u**.\n",
    "\n",
    "\n",
    "Now suppose the node **u** is representing the loss function and the dependency between nodes is parametrized each one by \n",
    "a parameter:\n",
    "\n",
    "![bp](backprop2.png)\n",
    "\n",
    "\n",
    "then as seen above backprop gives us a way to compute the partial derivative of the loss function with respect to any node,\n",
    "for instance for **r** : $\\frac{\\partial u}{\\partial r}$, based on the partial derivatives of the loss function with respect to its successors,\n",
    "for **r** it is **x** and **y**, thus $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$.\n",
    "\n",
    "So partial derivatives of the loss function **u** with respect to the nodes **x, y, r, t** are computed like the following, first we compute $\\frac{\\partial u}{\\partial x}$  and $\\frac{\\partial u}{\\partial y}$ directly because they are direct predecessors of **u**, then we go backward into the predecessors of **x** and **y** and compute $\\frac{\\partial u}{\\partial r}$ and $\\frac{\\partial t}{\\partial y}$ based on $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$. This procedure (backpropagation) is generalizable to any Direct Acyclic Graph (DAG).\n",
    "\n",
    "Now, having computed the partial derivative of the loss function with respect to the all the nodes with backpropagation, the derivatives of the loss function with respect to the parameters is easily obtained :\n",
    "\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial W_{rx}} =\\frac{\\partial u}{\\partial x}\\frac{\\partial x}{\\partial W_{rx}}$$\n",
    "$$\\frac{\\partial u}{\\partial W_{ry}} =\\frac{\\partial u}{\\partial y}\\frac{\\partial y}{\\partial W_{ry}}$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial W_{tx}} =\\frac{\\partial u}{\\partial x}\\frac{\\partial x}{\\partial W_{tx}}$$\n",
    "$$\\frac{\\partial u}{\\partial W_{ty}} =\\frac{\\partial u}{\\partial y}\\frac{\\partial y}{\\partial W_{ty}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what backpropagation gives for feedforward neural networks.\n",
    "\n",
    "We consider a neural network with **L** layers and we illustrate below two intermediate layers **l** and **l+1** and compute the partial derivatives of one layer given the partial derivatives of the next layer using backpropagation as given above.\n",
    "\n",
    "![backprop-nnet.png](backprop-nnet.png)\n",
    "\n",
    "the above computational graph translates into:\n",
    "\n",
    "$$E^{(l+1)}_j = \\sum_i H^{(l)}_i W^{(l)}_{i, j}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$H^{(l+1)}_j = g^{(l+1)}(E^{(l+1)}_j)$$\n",
    "\n",
    "where $g^{(l)}$ is the activation function of the layer **l + 1**.\n",
    "\n",
    "The vectorized version is:\n",
    "\n",
    "$$E^{(l+1)} = H^{(l)}W^{(l)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$H^{(l+1)} = g^{(l+1)}(E^{(l+1)})$$\n",
    "\n",
    "Now, if **L** is the loss function node, then:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial H^{(l)}_i} = \\sum_j \\frac{\\partial L}{\\partial E^{(l+1)}_j} W^{(l)}_{i,j}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial E^{(l+1)}_j} = \\frac{\\partial L}{H^{(l+1)}_j}g'( E^{(l+1)}_j)$$\n",
    "\n",
    "and the vectorized version is:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial H^{(l)}} = \\frac{\\partial L}{\\partial E^{(l+1)}}(W^{(l)})^T$ **(1)**\n",
    "\n",
    "$\\frac{\\partial L}{\\partial E^{(l+1)}} = \\frac{\\partial L}{\\partial H^{(l+1)}} * g'( E^{(l+1)})$ **(2)**\n",
    "\n",
    "the two above equations can be merged :\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial H^{(l)}} = \\frac{\\partial L}{\\partial H^{(l+1)}}g'( E^{(l+1)})(W^{(l)})^T$$\n",
    "\n",
    "now to find the derivatives of the loss with respect to $W^{(l)}$, it is simple:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^{(l)}_{i, j}} = \\frac{\\partial L}{\\partial E^{(l + 1)}_j}\\frac{\\partial E^{(l + 1)}_j}{\\partial W_{i, j}} = \\frac{\\partial L}{\\partial E^{(l + 1)}_j}H^{(l)}_i$$\n",
    "\n",
    "and the vectorized form is:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^{(l)}} = (H^{(l)})^T\\frac{\\partial L}{\\partial E^{(l + 1)}}  $ **(3)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use directly equations **(1)**, **(2)** and **(3)** to train a neural network, having defined the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use equations **(1)**, **(2)** and **(3)** to train a basic neural network with 2 layers.\n",
    "\n",
    "We will solve the same problem than before, so it is a classification problem and we will use the squared error as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba168be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "X, y = make_gaussian_quantiles(n_samples=500, n_features=2, n_classes=2)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1\n",
      " 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
      " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1\n",
      " 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that y is a binary variable, one way to predict values between 0 and 1 is to use the sigmoid  function $\\sigma$ as an activation function on the output layer, like with logisitic regression.\n",
    "\n",
    "Recall that : where $ \\sigma(a) = \\frac{1}{1 + exp(-a)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4ba1568d90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEMCAYAAADZDD24AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5CIiCadELiKScErkIiIJ9/9b1k+NV7sRvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba15aac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.arange(-5, 5, 0.1)\n",
    "plt.plot(a, 1./(1 + np.exp(-a)))\n",
    "plt.title(\"$\\sigma$ (sigmoid) activation function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the squared error as a loss function, defined by :\n",
    "    \n",
    "$$L(X, y) = \\frac{1}{2}\\sum_{i=1}^N (f(X_i) - y_i)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The direct predecessors of the loss function node are the values of the output layer, so we first compute the derivatives of the loss function with respect to the output layer.\n",
    "Assuming $O$ is the output layer,\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial O} = (O - Y)$$\n",
    "\n",
    "where $Y$ is the dataset \"true\" classes and $O$ the predicted ones, both are vectors\n",
    "of size $N$, each element representing one example.\n",
    "\n",
    "Then the derivation for the other layers is obtained directly using equations **(1)**, **(2)** and the derivation for the parameters from equation **(3)**. In equation **(3)** we did not include the derivatives for of the loss function with respect to the biases $b^{(l)}$, but it is straightforward and can be implied from equation **(3)**. You can think of the biases as part of the weights but multiplying inputs with the value of **1**, thus for biases,\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b_j^{(l)}} = \\frac{\\partial L}{\\partial E^{(l + 1)}_j}\\frac{\\partial E^{(l + 1)}_j}{\\partial b_j^{(l)}} = \\frac{\\partial L}{\\partial E^{(l + 1)}_j}$$\n",
    "\n",
    "and the vectorized form :\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b^{(l)}} = \\frac{\\partial L}{\\partial E^{(l + 1)}}  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network is defined like this again:\n",
    "\n",
    "- $h_1 = g^{(1)}(W^{(1)}x + b^{(1)})$ is the first hidden layer\n",
    "- $h_2 = g^{(2)}(W^{(2)} h_1 + b^{(2)})$ is the second hidden layer\n",
    "- $y = g^{(3)}(W^{(3)}h_2 + b^{(3)})$ is the output layer\n",
    "\n",
    "where\n",
    "\n",
    "$$g^{(1)}(a) = g^{(2)}(a) = g^{(3)}(a) = \\sigma(a) =  \\frac{1}{1 + exp(-a)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we initialize the parameters randomly, we will talk more about initialization and its importance later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = np.random.uniform(-0.001, 0.001, size=(X.shape[1], 100)) # 100 units in the first layer\n",
    "W2 = np.random.uniform(-0.01, 0.01, size=(100, 50)) # 50 units in the second layer\n",
    "W3 = np.random.uniform(-0.1, 0.1, size=(50, 1)) # 1 unit in the output layer\n",
    "\n",
    "b1= np.zeros(100,)\n",
    "b2 = np.zeros((50))\n",
    "b3 = np.zeros((1,))\n",
    "\n",
    "g = lambda x:1./(1 + np.exp(-x)) # the activation function is the same for all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(500, 2), h1:(500, 100), h2:(500, 50), y:(500,)\n",
      "accuracy : 0.5\n",
      "loss : 63.4276362327\n"
     ]
    }
   ],
   "source": [
    "# let's try a forward pass and check the initial value of the loss function\n",
    "N = y.shape[0]\n",
    "e1 = np.dot(X, W1) + b1\n",
    "h1 = g(e1)\n",
    "e2 = np.dot(h1, W2) + b2\n",
    "h2 = g(e2)\n",
    "e3 = np.dot(h2, W3) + b3\n",
    "o = g(e3)\n",
    "\n",
    "print(\"X:{0}, h1:{1}, h2:{2}, y:{3}\".format(X.shape, h1.shape, h2.shape, y.shape))\n",
    "\n",
    "# initial accuracy\n",
    "acc =  ((o>0.5)==y).mean()\n",
    "print(\"accuracy : {0}\".format(acc))\n",
    "# initial loss function value\n",
    "L = (0.5 * ((y[:, np.newaxis] - o)**2)).sum()\n",
    "print(\"loss : {0}\".format(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply backpropagation to get the derivatives of the loss with respect to the nodes\n",
    "\n",
    "notice that for sigmoid, $$g'(a) = g(a) * (1 - g(a))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_o = (o - y[:, np.newaxis] )\n",
    "d_e3 = d_o * o * (1 - o) # equation 2 + using the property of the sigmoid described just above\n",
    "d_h2 = np.dot(d_e3, W3.T) # equation 1\n",
    "d_e2 = d_h2 * h2 * (1 - h2) # equation 2 + + using the property of the sigmoid described just above\n",
    "d_h1 = np.dot(d_e2, W2.T) # equation 1\n",
    "d_e1 = d_h1 * h1 * (1 - h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the derivatives with respect to the parameters using equation **3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_W3 = np.dot(h2.T, d_e3)\n",
    "d_W2 = np.dot(h1.T, d_e2)\n",
    "d_W1 = np.dot(X.T, d_e1)\n",
    "\n",
    "d_b3 = d_e3.sum(axis=0)\n",
    "d_b2 = d_e2.sum(axis=0)\n",
    "d_b1 = d_e1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gradient check\n",
    "\n",
    "# Make sure the gradients are correct, use finite differences to compute\n",
    "# gradients numeriacally and compare it to the gradients obtained by\n",
    "# backpropgation\n",
    "\n",
    "def get_loss(X):\n",
    "    e1 = np.dot(X, W1) + b1\n",
    "    h1 = g(e1)\n",
    "    e2 = np.dot(h1, W2) + b2\n",
    "    h2 = g(e2)\n",
    "    e3 = np.dot(h2, W3) + b3\n",
    "    o = g(e3)\n",
    "    L = 0.5 * ((y[:, np.newaxis] - o)**2)\n",
    "    return L.sum()\n",
    "\n",
    "params = [W1, W2, W3, b1, b2, b3]\n",
    "d_params = [d_W1, d_W2, d_W3, d_b1, d_b2, d_b3]\n",
    "epsilon = 1e-6\n",
    "for p, d_p in zip(params, d_params):\n",
    "    p_flat = p.reshape((-1,))\n",
    "    d_p_flat = d_p.reshape((-1,))\n",
    "    for i in range(p_flat.shape[0]):\n",
    "        # use finite difference to compute gradients numerically\n",
    "        # and compare it with gradients computed from backprop\n",
    "        val = p_flat[i]\n",
    "        p_flat[i] = val + epsilon\n",
    "        La = get_loss(X)\n",
    "        p_flat[i] = val -  epsilon\n",
    "        Lb = get_loss(X)\n",
    "        p_flat[i] = val\n",
    "        grad = (La - Lb) / (2 * epsilon)\n",
    "        assert np.abs(grad - d_p_flat[i]) <= 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent tells us that to minimize the loss function **L** with respect to some parameters $\\Theta$ , we have to follow in each iteration the direction  defined by the **gradients** : -$\\frac{\\partial{L}}{\\partial{\\Theta}}$ scaled by a hyper-parameter $\\alpha$ which defines the step size at each iteration and is called the **learning rate**.\n",
    "\n",
    "\n",
    "Gradient descent can only converge to a local minimum. If the **learning rate** is too small, convergence towards the minimum is slow, but if the **learning rate** is too big, there is a risk that gradient descent diverges, so one seeks for the biggest value of the **learning rate** that do not diverge. Neural networks are very sensitive to the value **learning rate**, so it is important to tune it well.\n",
    "\n",
    "With **batch gradient descent**, we add up the **gradients** of the loss with respect to the parameters for the whole training set, it is very inefficient for large datasets. For large datasets, it is rather **stochastic gradient descent** which is used, where for its \"classical\" version we take randomly one example in each epoch and perform one update of the parameters based on it. **mini-batch gradient descent** is in between, instead of taking one example at a time, we take a **mini-batch** of examples (e.g 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do one step of gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 -= alpha * d_W3\n",
    "W2 -= alpha * d_W2\n",
    "W1 -= alpha * d_W1\n",
    "b3 -= alpha * d_b3\n",
    "b2 -= alpha * d_b2\n",
    "b1 -= alpha * d_b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and recompute the loss function value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss : ', 62.811671824013494)\n"
     ]
    }
   ],
   "source": [
    "N = y.shape[0]\n",
    "e1 = np.dot(X, W1) + b1\n",
    "h1 = g(e1)\n",
    "e2 = np.dot(h1, W2) + b2\n",
    "h2 = g(e2)\n",
    "e3 = np.dot(h2, W3) + b3\n",
    "o = g(e3)\n",
    "\n",
    "L = 0.5 * ((y[:, np.newaxis] - o)**2)\n",
    "print(\"loss : \", L.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now put everything together and apply gradient descent for several iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.04\n",
    "nb_epochs = 2000\n",
    "\n",
    "# Initialization\n",
    "nb_hidden1 = 10\n",
    "nb_hidden2 = 10\n",
    "\n",
    "W1 = np.random.uniform(-0.0001, 0.0001, size=(X.shape[1], nb_hidden1))\n",
    "W2 = np.random.uniform(-0.001, 0.001, size=(nb_hidden1, nb_hidden2)) # 50 units in the second layer\n",
    "W3 = np.random.uniform(-0.01, 0.01, size=(nb_hidden2, 1)) # 1 unit in the output layer\n",
    "\n",
    "b1= np.zeros(nb_hidden1,)\n",
    "b2 = np.zeros((nb_hidden2))\n",
    "b3 = np.zeros((1,))\n",
    "\n",
    "g = lambda x:1./(1 + np.exp(-x)) # the activation function is the same for all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500183830127334)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.502094573510334)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.523857718802049)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.770713261877148)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.444175705570601)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 84.153086635654333)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 95.138787784432765)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 70.297266719589544)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 81.446797296616268)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 77.328972395659548)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 74.334962601142763)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 71.72581420395629)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 69.624368396220632)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 68.035701507824072)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 66.791065551780576)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.847623896143332)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.111724431150961)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 64.548013310940021)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 64.10640554731819)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.764734942218105)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.495793371686894)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.286147655176222)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.120543892001251)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.990773204153555)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.88802902637498)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.807227327417358)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.74316542903216)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.69266172795745)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.652590136867524)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.620946483635436)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.595829468350694)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.575972062596442)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.56020783441361)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.54773446814734)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.537831922721921)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.529991929605217)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.523768012893754)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.518838258898889)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.514924912824284)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.511824206191612)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.509362925095957)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.507412177702264)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.505863745363413)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.50463615884312)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.503661711317278)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.502888944265841)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.502275450781951)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.501788748713608)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.501402254542228)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.501095476021462)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500851737488802)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500658117063992)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500504148521486)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500381686957006)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500284160496236)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500206436966778)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.50014438829011)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500094781502085)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.500055022758779)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.50002307588872)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.49999731060182)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499976444645839)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499959453051147)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.49994552836602)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499934025979357)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.49992443738666)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499916357020041)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.49990946456073)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499903504690685)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499898275530029)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499893616206982)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499889399369366)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499885523515118)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499881908178544)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499878489176112)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499875215531311)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499872046514753)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.49986894969043)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499865899065142)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499862873853573)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499859857316252)\n",
      "('accuracy : ', 0.498)\n",
      "('loss : ', 62.499856835983053)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499853798920135)\n",
      "('accuracy : ', 0.372)\n",
      "('loss : ', 62.499850737244394)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499847643658697)\n",
      "('accuracy : ', 0.50800000000000001)\n",
      "('loss : ', 62.499844512150176)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499841337693852)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.499838116066556)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.4998348436567)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.499831517350628)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499828134409512)\n",
      "('accuracy : ', 0.58199999999999996)\n",
      "('loss : ', 62.499824692400779)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499821189117668)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.499817622538679)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499813990774314)\n",
      "('accuracy : ', 0.51800000000000002)\n",
      "('loss : ', 62.499810292043662)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499806524638728)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.49980268691143)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499798777249211)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.49979479406835)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.499790735797028)\n",
      "('accuracy : ', 0.51400000000000001)\n",
      "('loss : ', 62.499786600872177)\n",
      "('accuracy : ', 0.502)\n",
      "('loss : ', 62.499782387727521)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.499778094792532)\n",
      "('accuracy : ', 0.502)\n",
      "('loss : ', 62.499773720483716)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.499769263204655)\n",
      "('accuracy : ', 0.504)\n",
      "('loss : ', 62.499764721339567)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.499760093253876)\n",
      "('accuracy : ', 0.504)\n",
      "('loss : ', 62.499755377289276)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.499750571764572)\n",
      "('accuracy : ', 0.504)\n",
      "('loss : ', 62.499745674971791)\n",
      "('accuracy : ', 0.51400000000000001)\n",
      "('loss : ', 62.499740685177017)\n",
      "('accuracy : ', 0.504)\n",
      "('loss : ', 62.499735600617271)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499730419501311)\n",
      "('accuracy : ', 0.51000000000000001)\n",
      "('loss : ', 62.499725140007087)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499719760282275)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.499714278442298)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499708692570664)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499703000717211)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499697200898453)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499691291095928)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499685269256446)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499679133290634)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.49967288107301)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499666510440754)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499660019193556)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499653405092552)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499646665860091)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.499639799178688)\n",
      "('accuracy : ', 0.52000000000000002)\n",
      "('loss : ', 62.499632802690783)\n",
      "('accuracy : ', 0.52000000000000002)\n",
      "('loss : ', 62.499625673997677)\n",
      "('accuracy : ', 0.52000000000000002)\n",
      "('loss : ', 62.499618410659238)\n",
      "('accuracy : ', 0.52400000000000002)\n",
      "('loss : ', 62.49961101019295)\n",
      "('accuracy : ', 0.52400000000000002)\n",
      "('loss : ', 62.499603470073453)\n",
      "('accuracy : ', 0.52400000000000002)\n",
      "('loss : ', 62.499595787731657)\n",
      "('accuracy : ', 0.52400000000000002)\n",
      "('loss : ', 62.49958796055428)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.499579985882903)\n",
      "('accuracy : ', 0.52800000000000002)\n",
      "('loss : ', 62.499571861013536)\n",
      "('accuracy : ', 0.52800000000000002)\n",
      "('loss : ', 62.499563583195609)\n",
      "('accuracy : ', 0.53000000000000003)\n",
      "('loss : ', 62.49955514963154)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.499546557475767)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.499537803834173)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.49952888576324)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.499519800269383)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.499510544308052)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.499501114783151)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.499491508546051)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.499481722394989)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.499471753074104)\n",
      "('accuracy : ', 0.56000000000000005)\n",
      "('loss : ', 62.499461597272798)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.49945125162477)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.499440712707298)\n",
      "('accuracy : ', 0.57199999999999995)\n",
      "('loss : ', 62.499429977040307)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.499419041085702)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.499407901246315)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.499396553865182)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.499384995224659)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.499373221545497)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.499361228986025)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.499349013641229)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.499336571541839)\n",
      "('accuracy : ', 0.58999999999999997)\n",
      "('loss : ', 62.499323898653479)\n",
      "('accuracy : ', 0.59199999999999997)\n",
      "('loss : ', 62.499310990875713)\n",
      "('accuracy : ', 0.59599999999999997)\n",
      "('loss : ', 62.499297844041095)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.499284453914342)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.499270816191292)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.499256926498013)\n",
      "('accuracy : ', 0.60199999999999998)\n",
      "('loss : ', 62.499242780389864)\n",
      "('accuracy : ', 0.60599999999999998)\n",
      "('loss : ', 62.499228373350491)\n",
      "('accuracy : ', 0.60599999999999998)\n",
      "('loss : ', 62.499213700790918)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 62.499198758048543)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.499183540386149)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.499168042990959)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.499152260973602)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.499136189367171)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499119823126158)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499103157125504)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499086186159502)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499068904940913)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499051308099808)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.499033390182603)\n",
      "('accuracy : ', 0.628)\n",
      "('loss : ', 62.499015145651022)\n",
      "('accuracy : ', 0.63)\n",
      "('loss : ', 62.498996568881054)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.498977654161919)\n",
      "('accuracy : ', 0.63600000000000001)\n",
      "('loss : ', 62.498958395695006)\n",
      "('accuracy : ', 0.63600000000000001)\n",
      "('loss : ', 62.498938787592834)\n",
      "('accuracy : ', 0.64000000000000001)\n",
      "('loss : ', 62.498918823878029)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.498898498482205)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.498877805244994)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.498856737912902)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.498835290138331)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.498813455478455)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.498791227394207)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.498768599249175)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.498745564308585)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.498722115738225)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498698246603382)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498673949867801)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.4986492183926)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498624044935283)\n",
      "('accuracy : ', 0.65800000000000003)\n",
      "('loss : ', 62.498598422148625)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.498572342579678)\n",
      "('accuracy : ', 0.65800000000000003)\n",
      "('loss : ', 62.498545798668729)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.498518782748221)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.498491287041816)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.498463303663279)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.498434824615558)\n",
      "('accuracy : ', 0.65800000000000003)\n",
      "('loss : ', 62.498405841789712)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498376346963958)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498346331802679)\n",
      "('accuracy : ', 0.65800000000000003)\n",
      "('loss : ', 62.498315787855454)\n",
      "('accuracy : ', 0.65800000000000003)\n",
      "('loss : ', 62.49828470655607)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.498253079221612)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498220897051525)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 62.498188151126669)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.49815483240841)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.498120931737773)\n",
      "('accuracy : ', 0.65000000000000002)\n",
      "('loss : ', 62.498086439834523)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.498051347296325)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.498015644597942)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.497979322090345)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.497942370000011)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.497904778428058)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.497866537349573)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.497827636612854)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.497788065938678)\n",
      "('accuracy : ', 0.65000000000000002)\n",
      "('loss : ', 62.497747814919734)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.497706873019851)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497665229573485)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497622873785076)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497579794728537)\n",
      "('accuracy : ', 0.65000000000000002)\n",
      "('loss : ', 62.497535981346729)\n",
      "('accuracy : ', 0.65200000000000002)\n",
      "('loss : ', 62.497491422450963)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497446106720574)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.497400022702507)\n",
      "('accuracy : ', 0.65000000000000002)\n",
      "('loss : ', 62.497353158810945)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497305503326999)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497257044398438)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.497207770039395)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.497157668130228)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.497106726417371)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.497054932513208)\n",
      "('accuracy : ', 0.64200000000000002)\n",
      "('loss : ', 62.497002273896058)\n",
      "('accuracy : ', 0.63600000000000001)\n",
      "('loss : ', 62.496948737910152)\n",
      "('accuracy : ', 0.63600000000000001)\n",
      "('loss : ', 62.496894311765743)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.496838982539188)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.496782737173149)\n",
      "('accuracy : ', 0.63)\n",
      "('loss : ', 62.496725562476783)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.496667445126114)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.496608371664351)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.496548328502328)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.496487301918989)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.49642527806197)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.496362242948273)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.496298182464891)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.496233082369685)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.496166928292197)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.496099705734622)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.496031400072866)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.495961996557583)\n",
      "('accuracy : ', 0.628)\n",
      "('loss : ', 62.495891480315457)\n",
      "('accuracy : ', 0.63)\n",
      "('loss : ', 62.495819836350464)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.495747049545237)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.495673104662572)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 62.495597986346979)\n",
      "('accuracy : ', 0.63)\n",
      "('loss : ', 62.495521679126369)\n",
      "('accuracy : ', 0.628)\n",
      "('loss : ', 62.495444167413822)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.49536543550947)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.495285467602415)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.495204247772918)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 62.495121759994504)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.495037988136339)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.494952915965598)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.494866527150009)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.49477880526058)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.49468973377428)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.494599296076984)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.494507475466548)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.494414255155874)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.494319618276265)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.4942235478808)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.494126026947932)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.49402703838512)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.493926565032723)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.493824589667909)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.493721095008787)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.493616063718697)\n",
      "('accuracy : ', 0.61399999999999999)\n",
      "('loss : ', 62.493509478410552)\n",
      "('accuracy : ', 0.61399999999999999)\n",
      "('loss : ', 62.493401321651419)\n",
      "('accuracy : ', 0.61399999999999999)\n",
      "('loss : ', 62.493291575967262)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.493180223847702)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.493067247751114)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.492952630109755)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.492836353335051)\n",
      "('accuracy : ', 0.61399999999999999)\n",
      "('loss : ', 62.49271839982314)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.492598751960472)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.492477392129601)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 62.492354302715157)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 62.492229466109976)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 62.492102864721403)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 62.491974480977674)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 62.491844297334666)\n",
      "('accuracy : ', 0.60599999999999998)\n",
      "('loss : ', 62.491712296282515)\n",
      "('accuracy : ', 0.60599999999999998)\n",
      "('loss : ', 62.491578460352713)\n",
      "('accuracy : ', 0.60599999999999998)\n",
      "('loss : ', 62.491442772125154)\n",
      "('accuracy : ', 0.60399999999999998)\n",
      "('loss : ', 62.491305214235439)\n",
      "('accuracy : ', 0.60399999999999998)\n",
      "('loss : ', 62.491165769382306)\n",
      "('accuracy : ', 0.60199999999999998)\n",
      "('loss : ', 62.491024420335307)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.490881149942524)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.490735941138595)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.490588776952762)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.490439640517209)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.49028851507547)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.490135383991088)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.489980230756345)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.489823039001216)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.489663792502434)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.489502475192779)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.489339071170392)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.489173564708466)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.489005940264775)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.488836182491653)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.488664276245885)\n",
      "('accuracy : ', 0.59599999999999997)\n",
      "('loss : ', 62.488490206598897)\n",
      "('accuracy : ', 0.59599999999999997)\n",
      "('loss : ', 62.488313958846973)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.488135518521645)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.487954871400213)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.487772003516369)\n",
      "('accuracy : ', 0.58999999999999997)\n",
      "('loss : ', 62.487586901170999)\n",
      "('accuracy : ', 0.58999999999999997)\n",
      "('loss : ', 62.487399550942932)\n",
      "('accuracy : ', 0.58999999999999997)\n",
      "('loss : ', 62.487209939700037)\n",
      "('accuracy : ', 0.58799999999999997)\n",
      "('loss : ', 62.487018054610203)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.486823883152532)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.486627413128573)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.486428632673665)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.486227530268337)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.486024094749766)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.4858183153233)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.485610181574053)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.485399683478498)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.48518681141617)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.484971556181257)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.484753908994357)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.484533861514173)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.484311405849148)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.484086534569215)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.483859240717379)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.483629517821385)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.483397359905254)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.483162761500765)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.482925717658958)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.482686223961409)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.482444276531552)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.482199872045783)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.481953007744451)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.481703681442838)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.481451891541852)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.481197637038541)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.480940917536628)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.480681733256588)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.480420085045743)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.480155974388026)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.479889403413495)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.479620374907668)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.47934889232058)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.479074959775488)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.478798582077388)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.478519764721106)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.4782385138992)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.477954836509369)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.47766874016164)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.477380233185102)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.477089324634264)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.476796024295034)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.476500342690301)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.476202291084988)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.475901881490728)\n",
      "('accuracy : ', 0.57199999999999995)\n",
      "('loss : ', 62.47559912667014)\n",
      "('accuracy : ', 0.57199999999999995)\n",
      "('loss : ', 62.475294040140469)\n",
      "('accuracy : ', 0.57199999999999995)\n",
      "('loss : ', 62.474986636176872)\n",
      "('accuracy : ', 0.56999999999999995)\n",
      "('loss : ', 62.474676929815125)\n",
      "('accuracy : ', 0.56999999999999995)\n",
      "('loss : ', 62.474364936853831)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.474050673856112)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.473734158150748)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.47341540783269)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.473094441763138)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.472771279568889)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.472445941641226)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.472118449134037)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.471788823961532)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.471457088795148)\n",
      "('accuracy : ', 0.56000000000000005)\n",
      "('loss : ', 62.471123267059909)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.470787382930119)\n",
      "('accuracy : ', 0.55800000000000005)\n",
      "('loss : ', 62.470449461324414)\n",
      "('accuracy : ', 0.55800000000000005)\n",
      "('loss : ', 62.470109527900185)\n",
      "('accuracy : ', 0.55800000000000005)\n",
      "('loss : ', 62.46976760904726)\n",
      "('accuracy : ', 0.55800000000000005)\n",
      "('loss : ', 62.469423731881022)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.469077924234732)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.468730214651323)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.468380632374355)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.468029207338439)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.467675970158837)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.467320952120517)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.466964185166461)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.466605701885193)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.466245535497869)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.46588371984447)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.465520289369437)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.465155279106611)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.464788724663592)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.464420662205285)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.464051128437021)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.463680160586861)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.46330779638744)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.462934074057074)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.462559032280438)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.462182710188458)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.461805147337863)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.461426383690046)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.46104645958949)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.460665415741616)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.460283293190216)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.459900133294397)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.459515977705081)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.459130868341042)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.458744847364684)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.45835795715729)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.45797024029406)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.457581739518716)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.457192497717926)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.456802557895401)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.456411963145797)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.456020756628348)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.455628981540428)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.455236681090902)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.454843898473356)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.454450676839301)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.454057059271285)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.453663088756045)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.453268808157574)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.452874260190342)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.452479487392559)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.452084532099548)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.45168943641724)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.451294242195928)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.450898991004173)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.450503724102944)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.450108482420092)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.449713306525105)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.449318236604171)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.44892331243571)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.448528573366175)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.448134058286406)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.447739805608393)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.44734585324251)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.446952238575321)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.446558998447912)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.446166169134756)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.445773786323237)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.445381885093752)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.444990499900499)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.444599664552847)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.444209412197523)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.443819775301385)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.443430785635016)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.443042474256984)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.442654871498924)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.442268006951338)\n",
      "('accuracy : ', 0.54400000000000004)\n",
      "('loss : ', 62.441881909450231)\n",
      "('accuracy : ', 0.54400000000000004)\n",
      "('loss : ', 62.441496607064551)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.441112127084374)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.440728496009996)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.440345739541769)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.439963882570858)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.43958294917077)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.439202962589732)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.438823945243996)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.438445918711864)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.43806890372862)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.437692920182386)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.437317987110667)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.436944122697852)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.43657134427346)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.436199668311318)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.435829110429417)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.435459685390683)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.435091407104494)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.434724288628992)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.434358342174157)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.433993579105618)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.433630009949248)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.433267644396452)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.432906491310177)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.432546558731538)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.432187853887214)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.431830383197493)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.431474152284792)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.431119165982963)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.430765428347101)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.430412942663907)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.430061711462599)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.429711736526372)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.429363018904269)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.429015558923616)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.428669356202846)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.428324409664697)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.4279807175499)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.427638277431171)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.427297086227533)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.426957140219017)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.426618435061549)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.426280965802256)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.425944726894855)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.425609712215319)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.425275915077805)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.42494332825062)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.424611943972423)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.424281753968508)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.423952749467183)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.423624921216238)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.423298259499447)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.422972754153101)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.422648394582531)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.422325169778638)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.422003068334419)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.42168207846133)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.421362188005716)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.421043384465023)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.420725655003963)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.420408986470541)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.420093365411944)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.419778778090276)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.419465210498025)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.419152648373512)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.418841077215959)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.418530482300461)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.418220848692719)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.417912161263409)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.417604404702459)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.417297563532983)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.416991622124939)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.416686564708584)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.416382375387442)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.416079038151295)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.415776536888536)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.4154748553985)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.415173977403271)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.414873886559249)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.414574566468467)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.414276000689455)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.413978172747903)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.413681066146822)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.413384664376608)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.413088950924561)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.41279390928419)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.412499522964154)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.412205775496844)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.411912650446681)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.411620131418104)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.411328202063082)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.411036846088507)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.410746047263096)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.410455789424105)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.410166056483604)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.409876832434534)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.409588101356384)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.409299847420641)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.409012054895868)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.408724708152519)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.408437791667467)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.408151290028243)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.407865187936977)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.407579470214117)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.407294121801797)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.407009127767068)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.406724473304706)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.406440143739914)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.406156124530753)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.405872401270258)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.405588959688401)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.405305785653823)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.405022865175326)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.404740184403138)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.404457729630039)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.404175487292235)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.40389344397002)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.403611586388358)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.403329901417159)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.403048376071453)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.402766997511435)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.402485753042257)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.402204630113729)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.401923616319877)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.401642699398323)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.401361867229596)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.401081107836227)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.400800409381802)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.400519760169843)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.40023914864264)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.399958563379911)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.399677993097384)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.399397426645336)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.399116853006944)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.398836261296665)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.398555640758453)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.398274980763937)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.397994270810486)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.397713500519345)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.397432659633495)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.397151738015644)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.396870725646082)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.396589612620495)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.396308389147762)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.396027045547662)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.395745572248593)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.395463959785239)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.395182198796192)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.394900280021609)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.394618194300733)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.394335932569497)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.39405348585808)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.393770845288415)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.393488002071734)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.393204947506078)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.39292167297377)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.392638169938976)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.392354429945129)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.392070444612457)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.391786205635512)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.391501704780595)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.391216933883321)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.390931884846104)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.390646549635662)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.390360920280564)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.390074988868733)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.389788747545033)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.389502188508814)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.389215304011422)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.388928086353914)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.38864052788454)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.388352620996415)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.388064358125156)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.387775731746515)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.387486734374093)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.387197358556968)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.386907596877435)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.386617441948779)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.386326886412931)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.386035922938362)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.385744544217744)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.385452742965839)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.385160511917348)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.384867843824708)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.384574731455999)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.384281167592853)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.383987145028364)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.383692656564989)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.383397695012583)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.383102253186337)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.382806323904774)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.382509899987795)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.382212974254692)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.381915539522282)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.381617588602936)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.381319114302649)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.381020109419239)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.380720566740479)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.380420479042201)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.380119839086525)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.379818639620041)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.379516873372026)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.379214533052689)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.37891161135137)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.378608100934848)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.378303994445623)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.377999284500191)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.377693963687328)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.377388024566471)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.377081459666009)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.376774261481643)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.376466422474749)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.376157935070736)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.375848791657489)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.375538984583635)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.375228506157086)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.374917348643379)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.37460550426411)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.374292965195359)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.373979723566151)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.373665771456871)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.373351100897715)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.373035703867203)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.372719572290571)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.372402698038272)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.372085072924449)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.371766688705385)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.371447537078041)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.371127609678432)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.370806898080247)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.370485393793189)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.370163088261563)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.369839972862721)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.369516038905545)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.369191277628893)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.368865680200173)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.368539237713719)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.36821194118933)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.367883781570711)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.367554749723922)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.367224836435902)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.366894032412858)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.366562328278761)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.366229714573748)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.365896181752589)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.365561720183109)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.365226320144608)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.364889971826244)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.364552665325483)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.364214390646453)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.363875137698329)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.363534896293721)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.363193656147004)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.362851406872693)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.362508137983738)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.362163838889884)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.361818498895929)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.361472107200079)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.361124652892073)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.360776124951705)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.36042651224674)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.36007580353148)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.359723987444553)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.359371052507655)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.359016987123006)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.358661779572422)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.35830541801424)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.357947890482919)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.357589184885349)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.357229289001069)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.356868190477613)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.356505876831932)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.356142335444112)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.355777553560728)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.355411518286012)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.355044216588283)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.354675635287151)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.35430576106485)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.353934580447117)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.353562079822375)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.35318824541249)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.352813063304801)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.352436519406353)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.352058599496829)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.351679289155946)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.351298573850627)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.35091643881843)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.350532869211023)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.350147849905071)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.34976136573917)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.349373401204303)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.34898394083649)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.348592968706257)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.348200469072559)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.347806425535104)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.347410822129206)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.347013641909925)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.346614868796635)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.346214485195603)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.345812475129954)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.345408820231263)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.345003505096024)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.344596510512645)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.344187822728287)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.343777422019429)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.343365298964372)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.342951435312003)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.342535833186218)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.342118483763741)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.341699421453782)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.341278675322215)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.340856374756441)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.340432684292452)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.340008024856957)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.33958302613447)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.339159033366528)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.33873825358252)\n",
      "('accuracy : ', 0.54400000000000004)\n",
      "('loss : ', 62.33832503350115)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.337926931162656)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.337558213756658)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.337244727580483)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.337033949901382)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.337015000231546)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.337347386655765)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.338342789744139)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.340538639507798)\n",
      "('accuracy : ', 0.46000000000000002)\n",
      "('loss : ', 62.345046105367125)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.353657434570877)\n",
      "('accuracy : ', 0.40999999999999998)\n",
      "('loss : ', 62.370426608971151)\n",
      "('accuracy : ', 0.66400000000000003)\n",
      "('loss : ', 62.40107870425291)\n",
      "('accuracy : ', 0.38)\n",
      "('loss : ', 62.460708087672252)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.565046553840943)\n",
      "('accuracy : ', 0.48999999999999999)\n",
      "('loss : ', 62.769785321285269)\n",
      "('accuracy : ', 0.502)\n",
      "('loss : ', 63.093667171651873)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.720503398930063)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 64.459930701320445)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.791664526644965)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 66.3292511800433)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 67.62072326789206)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 66.750711873320256)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 67.311867836922019)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 66.038505892276206)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 66.182954629853455)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.212647773600949)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 65.191938784695708)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 64.52451257518004)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 64.449313778278224)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.995364244614962)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.91081955938585)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.59966548625485)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.522612464589599)\n",
      "('accuracy : ', 0.502)\n",
      "('loss : ', 63.306654785423802)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.242000119998515)\n",
      "('accuracy : ', 0.502)\n",
      "('loss : ', 63.090051829906102)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 63.037915300003483)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.929514696711934)\n",
      "('accuracy : ', 0.496)\n",
      "('loss : ', 62.888321004613005)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.809918587931143)\n",
      "('accuracy : ', 0.47999999999999998)\n",
      "('loss : ', 62.777700277887121)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.720221474674254)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.695130758591461)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.652426819774107)\n",
      "('accuracy : ', 0.45200000000000001)\n",
      "('loss : ', 62.632902009056892)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.600758763617122)\n",
      "('accuracy : ', 0.438)\n",
      "('loss : ', 62.585546005694546)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.561042968431416)\n",
      "('accuracy : ', 0.41399999999999998)\n",
      "('loss : ', 62.54916331890594)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.530254700340166)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.520955949783328)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.506193746391546)\n",
      "('accuracy : ', 0.38)\n",
      "('loss : ', 62.498903227133738)\n",
      "('accuracy : ', 0.63)\n",
      "('loss : ', 62.487252302748118)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.481536417520971)\n",
      "('accuracy : ', 0.64000000000000001)\n",
      "('loss : ', 62.472249789794603)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.46778144785354)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.460315384164318)\n",
      "('accuracy : ', 0.38600000000000001)\n",
      "('loss : ', 62.456848719573095)\n",
      "('accuracy : ', 0.65000000000000002)\n",
      "('loss : ', 62.4508044182775)\n",
      "('accuracy : ', 0.38800000000000001)\n",
      "('loss : ', 62.448155593973397)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.44323879303596)\n",
      "('accuracy : ', 0.39200000000000002)\n",
      "('loss : ', 62.441271652614105)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.437264445440199)\n",
      "('accuracy : ', 0.38800000000000001)\n",
      "('loss : ', 62.435879932514766)\n",
      "('accuracy : ', 0.66400000000000003)\n",
      "('loss : ', 62.432620979460268)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.431749454632829)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.429120030006757)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.428715817016275)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.426629958706371)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.42666762321565)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.425065203008366)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.425537205981414)\n",
      "('accuracy : ', 0.66000000000000003)\n",
      "('loss : ', 62.42437910724373)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.425294582825231)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.424559418388725)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.425943907919617)\n",
      "('accuracy : ', 0.66400000000000003)\n",
      "('loss : ', 62.425625872527895)\n",
      "('accuracy : ', 0.38600000000000001)\n",
      "('loss : ', 62.4275219051626)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.427629456628701)\n",
      "('accuracy : ', 0.39000000000000001)\n",
      "('loss : ', 62.43009790400734)\n",
      "('accuracy : ', 0.66200000000000003)\n",
      "('loss : ', 62.430653017719877)\n",
      "('accuracy : ', 0.39200000000000002)\n",
      "('loss : ', 62.433775163046782)\n",
      "('accuracy : ', 0.65400000000000003)\n",
      "('loss : ', 62.434812910206695)\n",
      "('accuracy : ', 0.39000000000000001)\n",
      "('loss : ', 62.438693154330238)\n",
      "('accuracy : ', 0.64800000000000002)\n",
      "('loss : ', 62.440261313541939)\n",
      "('accuracy : ', 0.38400000000000001)\n",
      "('loss : ', 62.445030380201374)\n",
      "('accuracy : ', 0.64600000000000002)\n",
      "('loss : ', 62.447188698186665)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.45300707910166)\n",
      "('accuracy : ', 0.63800000000000001)\n",
      "('loss : ', 62.455825640357986)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.46288681373612)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 62.466442754750275)\n",
      "('accuracy : ', 0.38)\n",
      "('loss : ', 62.474975390723927)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.479346909256591)\n",
      "('accuracy : ', 0.38200000000000001)\n",
      "('loss : ', 62.489614822686136)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.494871127304563)\n",
      "('accuracy : ', 0.40400000000000003)\n",
      "('loss : ', 62.507169161859409)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.513354786630657)\n",
      "('accuracy : ', 0.42799999999999999)\n",
      "('loss : ', 62.5279981936377)\n",
      "('accuracy : ', 0.56999999999999995)\n",
      "('loss : ', 62.535110177961712)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.552414598218505)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.560371748285803)\n",
      "('accuracy : ', 0.45200000000000001)\n",
      "('loss : ', 62.580621015572845)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.589226277320975)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.612626542388661)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.621526821445379)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.648148606604863)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.656801100120063)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.686516130406261)\n",
      "('accuracy : ', 0.52000000000000002)\n",
      "('loss : ', 62.694175242411788)\n",
      "('accuracy : ', 0.48599999999999999)\n",
      "('loss : ', 62.726601466719885)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.732342964219626)\n",
      "('accuracy : ', 0.48999999999999999)\n",
      "('loss : ', 62.766816545799955)\n",
      "('accuracy : ', 0.51000000000000001)\n",
      "('loss : ', 62.769611983741449)\n",
      "('accuracy : ', 0.496)\n",
      "('loss : ', 62.805205184268736)\n",
      "('accuracy : ', 0.51000000000000001)\n",
      "('loss : ', 62.804047071701262)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.839642382139985)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.833700873622114)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.868114831577415)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.856888107896346)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.889019285812651)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.872433665044859)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.901398162415717)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.879826961267604)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.90504824783568)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.879245743448273)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.900482316765228)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.871456859484574)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.888771901255438)\n",
      "('accuracy : ', 0.50600000000000001)\n",
      "('loss : ', 62.857636954222471)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.871329155699513)\n",
      "('accuracy : ', 0.50800000000000001)\n",
      "('loss : ', 62.839168711987682)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.849688075731407)\n",
      "('accuracy : ', 0.51000000000000001)\n",
      "('loss : ', 62.817459100478359)\n",
      "('accuracy : ', 0.496)\n",
      "('loss : ', 62.825327435744981)\n",
      "('accuracy : ', 0.51000000000000001)\n",
      "('loss : ', 62.793805811686752)\n",
      "('accuracy : ', 0.48999999999999999)\n",
      "('loss : ', 62.799553554564355)\n",
      "('accuracy : ', 0.51200000000000001)\n",
      "('loss : ', 62.769318083015897)\n",
      "('accuracy : ', 0.48999999999999999)\n",
      "('loss : ', 62.773441271707576)\n",
      "('accuracy : ', 0.51600000000000001)\n",
      "('loss : ', 62.744884655105793)\n",
      "('accuracy : ', 0.48799999999999999)\n",
      "('loss : ', 62.747820558612574)\n",
      "('accuracy : ', 0.51800000000000002)\n",
      "('loss : ', 62.721175759588036)\n",
      "('accuracy : ', 0.47999999999999998)\n",
      "('loss : ', 62.723293072639592)\n",
      "('accuracy : ', 0.52000000000000002)\n",
      "('loss : ', 62.69866570349113)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.700264673041133)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.677665160141267)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.678983592132084)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.658355641420869)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.659577742403755)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.640821669496837)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.642087685989694)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.625078452591751)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.626493893969013)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.611094373739924)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.612738196879306)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.598808473854824)\n",
      "('accuracy : ', 0.45400000000000001)\n",
      "('loss : ', 62.600739994118776)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.588143539101949)\n",
      "('accuracy : ', 0.45000000000000001)\n",
      "('loss : ', 62.590408060614337)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.579015551522389)\n",
      "('accuracy : ', 0.44800000000000001)\n",
      "('loss : ', 62.581648828529495)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.571340252278915)\n",
      "('accuracy : ', 0.44600000000000001)\n",
      "('loss : ', 62.574371942114794)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.565037479256745)\n",
      "('accuracy : ', 0.44400000000000001)\n",
      "('loss : ', 62.568493754712854)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.560033823936777)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.563939297858397)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.556264033592029)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.560643123317789)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.553671477281597)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.558549308193037)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.552207903146034)\n",
      "('accuracy : ', 0.438)\n",
      "('loss : ', 62.557610823019132)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.551832641233986)\n",
      "('accuracy : ', 0.438)\n",
      "('loss : ', 62.557788392346033)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.552511349751732)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.559048924896523)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.554214362003414)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.561363554443076)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.5569146654408)\n",
      "('accuracy : ', 0.44)\n",
      "('loss : ', 62.56470531211631)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.560585532823715)\n",
      "('accuracy : ', 0.44400000000000001)\n",
      "('loss : ', 62.569046445787599)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.565197828745042)\n",
      "('accuracy : ', 0.44600000000000001)\n",
      "('loss : ', 62.574355412917718)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.57071703322444)\n",
      "('accuracy : ', 0.44600000000000001)\n",
      "('loss : ', 62.580593600433275)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.577100057969105)\n",
      "('accuracy : ', 0.44800000000000001)\n",
      "('loss : ', 62.587711868778968)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.584291979351853)\n",
      "('accuracy : ', 0.45200000000000001)\n",
      "('loss : ', 62.595647075641935)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.592222872104252)\n",
      "('accuracy : ', 0.45400000000000001)\n",
      "('loss : ', 62.60431880345574)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.600804992845113)\n",
      "('accuracy : ', 0.46000000000000002)\n",
      "('loss : ', 62.613626585194403)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.609930622514831)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.623447982147951)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.619470917227574)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.633637898293344)\n",
      "('accuracy : ', 0.53400000000000003)\n",
      "('loss : ', 62.629276121039396)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.644029499721029)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.63917744523124)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.654437027939906)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.648990805768179)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.66466064451712)\n",
      "('accuracy : ', 0.53000000000000003)\n",
      "('loss : ', 62.658522433270399)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.674493227269686)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.667576143091317)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.683728778938757)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.67596180852054)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.692171849080829)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.683504362050364)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.699647160481746)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.690052505851973)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.706008522706767)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.695486281546444)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.711146141165813)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.699722747889808)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.714991596070242)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.702719231455809)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.717520045652037)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.704473911100635)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.718749549608056)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.705023816154352)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.718737747370497)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.704440602972696)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.717576401958212)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.702824679216846)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.715384493607509)\n",
      "('accuracy : ', 0.52200000000000002)\n",
      "('loss : ', 62.700298346443311)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.71230060423153)\n",
      "('accuracy : ', 0.52400000000000002)\n",
      "('loss : ', 62.696998629683009)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.708475285157846)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.693070377363298)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.704063975100595)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.6886600766301)\n",
      "('accuracy : ', 0.47399999999999998)\n",
      "('loss : ', 62.699220868697893)\n",
      "('accuracy : ', 0.52600000000000002)\n",
      "('loss : ', 62.683910670072763)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.694093961910035)\n",
      "('accuracy : ', 0.53000000000000003)\n",
      "('loss : ', 62.678957507132694)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.688821344761053)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.673925435426966)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.683528689500896)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.668926942863962)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.678327798678716)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.664061202014423)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.673316030893332)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.659413839699411)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.668576405751715)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.655057250412014)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.664178195661215)\n",
      "('accuracy : ', 0.53800000000000003)\n",
      "('loss : ', 62.651051284563394)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.660177832469017)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.647444164859607)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.656619984844866)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.644273510949915)\n",
      "('accuracy : ', 0.46400000000000002)\n",
      "('loss : ', 62.653538692570876)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.64156737995885)\n",
      "('accuracy : ', 0.46400000000000002)\n",
      "('loss : ', 62.650958473143312)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.63934525617195)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.648895342338236)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.637618945685105)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.647357712770898)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.63639335078453)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.646347152860741)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.635667114268202)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.645859003307883)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.635433136215141)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.645882859710468)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.635678975332844)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.6464029388559)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.636387154425492)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.647398352985235)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.637535395094353)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.648843321301293)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.639096810735751)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.650707351352303)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.641040089328655)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.652955424696984)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.643329698355991)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.655548221339544)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.645926143340304)\n",
      "('accuracy : ', 0.46200000000000002)\n",
      "('loss : ', 62.658442415624648)\n",
      "('accuracy : ', 0.54400000000000004)\n",
      "('loss : ', 62.648786308716083)\n",
      "('accuracy : ', 0.46400000000000002)\n",
      "('loss : ', 62.661591072404619)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.6518639049565)\n",
      "('accuracy : ', 0.46400000000000002)\n",
      "('loss : ', 62.66494416619517)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.655110038975565)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.668449237736958)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.658473915971072)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.672052192110563)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.661903670424309)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.675698230817261)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.665347312555568)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.679332897822761)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.668753765017755)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.682903207490654)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.672073954033195)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.686358811775484)\n",
      "('accuracy : ', 0.53800000000000003)\n",
      "('loss : ', 62.675261910646668)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.689653156173691)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.678275832290907)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.692744569749181)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.681079053212216)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.695597234729604)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.683640874868644)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.698181985919689)\n",
      "('accuracy : ', 0.53400000000000003)\n",
      "('loss : ', 62.685937214110922)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.700476899178589)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.687951037218461)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.702467640634076)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.68967256070264)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.704147562927133)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.691099213926577)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.705517550132932)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.692235372639601)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.70658562759909)\n",
      "('accuracy : ', 0.53200000000000003)\n",
      "('loss : ', 62.693091885175619)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.707366365461169)\n",
      "('accuracy : ', 0.53400000000000003)\n",
      "('loss : ', 62.693685423256987)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.707880114055939)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.694037696379922)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.708152115299015)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.694174572347933)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.708211536221377)\n",
      "('accuracy : ', 0.53600000000000003)\n",
      "('loss : ', 62.694125146776358)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.708090469565036)\n",
      "('accuracy : ', 0.53800000000000003)\n",
      "('loss : ', 62.693920801749265)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.707822942225498)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.693594288928871)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.707443966184691)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.693178866062325)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.706988659246946)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.692707508767405)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.706491455172255)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.692212212390508)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.705985415369682)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.691723392162629)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.705501647676414)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.691269384213541)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.705068832230396)\n",
      "('accuracy : ', 0.54000000000000004)\n",
      "('loss : ', 62.690876045462119)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.704712850203592)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.690566447054579)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.704456508210704)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.690360653833167)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.704319349450863)\n",
      "('accuracy : ', 0.54200000000000004)\n",
      "('loss : ', 62.690275581160918)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.704317541907876)\n",
      "('accuracy : ', 0.54400000000000004)\n",
      "('loss : ', 62.690324920126457)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.704463834021077)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.690519122509102)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.704767568922023)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.69086543769145)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.705234749395565)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.691367994776151)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.705868146972691)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.692027924323845)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.706667449827272)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.692843515239801)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.707629445294415)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.693810403285894)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.708748233750327)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.694921788401572)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.710015471223869)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.696168678434631)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.711420638410772)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.697540156987969)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.712951333726465)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.699023672893219)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.714593587685499)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.700605348357854)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.716332195283286)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.702270302158759)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.718151062250286)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.704002983445299)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.720033560138724)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.705787510860191)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.721962884286555)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.707608010880207)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.72392240788664)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.709448948617236)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.725896024769341)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.711295443888289)\n",
      "('accuracy : ', 0.46600000000000003)\n",
      "('loss : ', 62.7278684731684)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.713133565230009)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.729825632748614)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.714950594745375)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.73175478756454)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.716735257244771)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.733644848397205)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.718477908068735)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.735486529054739)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.720170675213211)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.737272472662085)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.721807552853932)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.738997325625519)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.723384444996356)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.740657758737235)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.724899159666137)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.74225243667798)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.726351355700508)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.743781938877142)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.727742445712224)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.745248636204906)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.729075460095643)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.7466565292263)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.730354877970278)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.748011054690465)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.731586431677123)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.749318867534178)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.732776891843471)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.750587605945981)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.733933840126319)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.751825646988856)\n",
      "('accuracy : ', 0.54600000000000004)\n",
      "('loss : ', 62.735065436559047)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.753041859951892)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.736180188006237)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.754245364049126)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.737286723626077)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.755445296360733)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.738393582504528)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.756650595078412)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.739509017811301)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.757869802225315)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.74064082098247)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.759110889118837)\n",
      "('accuracy : ', 0.54800000000000004)\n",
      "('loss : ', 62.741796168597304)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.760381106969476)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.742981493816941)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.761686864186586)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.744202383511535)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.76303363121167)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.745463501530949)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.764425873027648)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.746768537978028)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.765867008901566)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.748120183819779)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.767359398403514)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.749520129716515)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.768904352298442)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.750969087555163)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.770502166523656)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.752466832831701)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.772152177132078)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.754012265734481)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.773852833797477)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.755603488528926)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.775601789234926)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.757237896633868)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.77739600169059)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.758912280610978)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.779231847498664)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.760622936163884)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.78110524059592)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.762365779168121)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.783011755830273)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.764136462732054)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.784946752906265)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.765930493328291)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.786905497882515)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.767743343139088)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.788883279278167)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.769570555930578)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.790875516059316)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.771407844009062)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.792877855060006)\n",
      "('accuracy : ', 0.55000000000000004)\n",
      "('loss : ', 62.773251174115082)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.794886255741211)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.775096840469779)\n",
      "('accuracy : ', 0.46800000000000003)\n",
      "('loss : ', 62.796897060596237)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.776941523594843)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.798907049959894)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.778782333967264)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.800913480457332)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.780616840029936)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.80291410681928)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.782443080541547)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.804907187276619)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.78425956169788)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.806891473210385)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.786065239876123)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.808866184158262)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.787859491228957)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.810830969650667)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.789642069675381)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.812785859657069)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.791413055089905)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.814731205659122)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.793172793676931)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.816667614525969)\n",
      "('accuracy : ', 0.55200000000000005)\n",
      "('loss : ', 62.79492183262812)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.818595877448267)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.796660851200173)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.820516896193276)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.798390590320295)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.822431608877729)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.800111782733325)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.824340917326666)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.801825085555585)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.826245617902401)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.803531016904003)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.828146337459216)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.805229898035904)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.830043475815302)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.806921802172731)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.831937155846035)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.808606510902294)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.833827182000469)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.810283478765271)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.83571300773594)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.811951806343856)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.837593712063708)\n",
      "('accuracy : ', 0.55400000000000005)\n",
      "('loss : ', 62.813610221889896)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.839467985107838)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.81525707126454)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.841334122309085)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.816890315717352)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.843190026659819)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.818507536815481)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.845033218141594)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.820105947647363)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.846860849357405)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.821682409273791)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.848669726209124)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.823233451285489)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.850456332370399)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.824755295251009)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.852216856246073)\n",
      "('accuracy : ', 0.55600000000000005)\n",
      "('loss : ', 62.826243879803627)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.853947219092035)\n",
      "('accuracy : ', 0.55800000000000005)\n",
      "('loss : ', 62.827694886118834)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.855643102993035)\n",
      "('accuracy : ', 0.56000000000000005)\n",
      "('loss : ', 62.829103762575471)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.857299977457799)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.830465747468281)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.858913123487099)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 62.831775888745781)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.860477654096997)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.833029059878548)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.861988530430899)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.834219971114713)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.863440572762627)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.835343175544438)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.864828465873579)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.836393069566988)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.866146758470585)\n",
      "('accuracy : ', 0.56399999999999995)\n",
      "('loss : ', 62.83736388752569)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.867389856491869)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.838249690441586)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.868552010318552)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.839044348927096)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.869627296061765)\n",
      "('accuracy : ', 0.56599999999999995)\n",
      "('loss : ', 62.839741520494925)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.8706095912259)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.84033462158456)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.871492545150929)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.840816794710548)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.872269544708232)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.841180871185429)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.872933675762482)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.841419329888794)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.873477680915585)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.841524252537312)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.873893914017636)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.841487275864317)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.874174291865685)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.841299541037912)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.874310243416062)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.840951640541732)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.874292656712768)\n",
      "('accuracy : ', 0.56799999999999995)\n",
      "('loss : ', 62.840433562610094)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.874111823587484)\n",
      "('accuracy : ', 0.56999999999999995)\n",
      "('loss : ', 62.839734633157143)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.87375738201888)\n",
      "('accuracy : ', 0.56999999999999995)\n",
      "('loss : ', 62.838843454969599)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.873218255856273)\n",
      "('accuracy : ', 0.57199999999999995)\n",
      "('loss : ', 62.837747843748275)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.872482591416812)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.836434760390134)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.871537690263295)\n",
      "('accuracy : ', 0.57399999999999995)\n",
      "('loss : ', 62.834890238701647)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.870369937262069)\n",
      "('accuracy : ', 0.57599999999999996)\n",
      "('loss : ', 62.833099307529629)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.86896472281181)\n",
      "('accuracy : ', 0.57799999999999996)\n",
      "('loss : ', 62.831045906088569)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.867306357926147)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.828712791055665)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.86537798064596)\n",
      "('accuracy : ', 0.57999999999999996)\n",
      "('loss : ', 62.82608143379565)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.863161452053362)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.823131905866248)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.860637239955551)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.819842750740541)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.857784288103488)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.816190839459665)\n",
      "('accuracy : ', 0.46999999999999997)\n",
      "('loss : ', 62.854579868603537)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.812151207696338)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.850999414968868)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.807696871460152)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.847016333035754)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.802798618403976)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.84260178673722)\n",
      "('accuracy : ', 0.58399999999999996)\n",
      "('loss : ', 62.797424771392556)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.83772445547848)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.791540920662044)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.83235025959501)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.785109620528971)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.826442050095402)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.778090046195047)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.819959258603241)\n",
      "('accuracy : ', 0.58599999999999997)\n",
      "('loss : ', 62.770437605740099)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.812857503124889)\n",
      "('accuracy : ', 0.58999999999999997)\n",
      "('loss : ', 62.762103501903113)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.805088145002983)\n",
      "('accuracy : ', 0.59199999999999997)\n",
      "('loss : ', 62.753034237733338)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.796597792200032)\n",
      "('accuracy : ', 0.59199999999999997)\n",
      "('loss : ', 62.743171059671894)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.78732774394247)\n",
      "('accuracy : ', 0.59399999999999997)\n",
      "('loss : ', 62.732449331140458)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.777213371817638)\n",
      "('accuracy : ', 0.59599999999999997)\n",
      "('loss : ', 62.720797829333776)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.766183432767278)\n",
      "('accuracy : ', 0.59599999999999997)\n",
      "('loss : ', 62.708137957739801)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.754159310226967)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.694382867107983)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.741054181161971)\n",
      "('accuracy : ', 0.59799999999999998)\n",
      "('loss : ', 62.679436478390471)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.726772109294359)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.66319240295249)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.711207068899228)\n",
      "('accuracy : ', 0.59999999999999998)\n",
      "('loss : ', 62.645532758602528)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.694241909868282)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 62.626326885474171)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.675747284264361)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 62.605429974530296)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.655580568635742)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 62.58268163486899)\n",
      "('accuracy : ', 0.47199999999999998)\n",
      "('loss : ', 62.63358483665678)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.557904445926127)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.609587965404714)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 62.530902569384459)\n",
      "('accuracy : ', 0.47599999999999998)\n",
      "('loss : ', 62.583401998369567)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 62.501460535722487)\n",
      "('accuracy : ', 0.47799999999999998)\n",
      "('loss : ', 62.554822941890137)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.469342374422673)\n",
      "('accuracy : ', 0.48599999999999999)\n",
      "('loss : ', 62.523631241432156)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 62.43429132655578)\n",
      "('accuracy : ', 0.48999999999999999)\n",
      "('loss : ', 62.489593270638004)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.396030462930916)\n",
      "('accuracy : ', 0.498)\n",
      "('loss : ', 62.452464266251823)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.354264624310609)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.411993245589692)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 62.308684187449366)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.367930528079526)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.258971213173275)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.320038508977731)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.204808502749245)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.268106239360876)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.145891906868002)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.211968064295874)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.081945808588891)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.151525951324068)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 62.012740940341004)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.086774085313749)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 61.938112513349012)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 62.017822708030216)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 61.857975003859416)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.944915984282709)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 61.772327922099748)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.868435928909918)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 61.681244729866535)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.788881393926758)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 61.584835321627573)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.706808493662784)\n",
      "('accuracy : ', 0.62)\n",
      "('loss : ', 61.483172216085308)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.622718124974774)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 61.376173635995436)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.536879988857677)\n",
      "('accuracy : ', 0.61799999999999999)\n",
      "('loss : ', 61.263445397190608)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.449094025888527)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 61.144099759899511)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.358411431502297)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 61.016591318081652)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.2628650092486)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 60.878628593087065)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.15927976698989)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 60.727218916272946)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 61.043229551906514)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 60.558869049196943)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 60.909161693105013)\n",
      "('accuracy : ', 0.60799999999999998)\n",
      "('loss : ', 60.369899818978283)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 60.750643761448202)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 60.156773264367281)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 60.560638109798099)\n",
      "('accuracy : ', 0.60999999999999999)\n",
      "('loss : ', 59.916317452545378)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 60.331719960252315)\n",
      "('accuracy : ', 0.61399999999999999)\n",
      "('loss : ', 59.64577825446932)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 60.056216744070454)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 59.342693745107184)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 59.726309723577728)\n",
      "('accuracy : ', 0.61599999999999999)\n",
      "('loss : ', 59.004628699877955)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 59.334160418457984)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 58.628811151671847)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 58.872106838318658)\n",
      "('accuracy : ', 0.622)\n",
      "('loss : ', 58.211704440584768)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 58.332949626013374)\n",
      "('accuracy : ', 0.624)\n",
      "('loss : ', 57.748554136630489)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 57.710335509123411)\n",
      "('accuracy : ', 0.626)\n",
      "('loss : ', 57.232977279981164)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 56.999239564721691)\n",
      "('accuracy : ', 0.628)\n",
      "('loss : ', 56.656704319079687)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 56.196535424083123)\n",
      "('accuracy : ', 0.63200000000000001)\n",
      "('loss : ', 56.009630834667938)\n",
      "('accuracy : ', 0.5)\n",
      "('loss : ', 55.301619889168833)\n",
      "('accuracy : ', 0.63600000000000001)\n",
      "('loss : ', 55.280371582565245)\n",
      "('accuracy : ', 0.56200000000000006)\n",
      "('loss : ', 54.317035553402498)\n",
      "('accuracy : ', 0.63800000000000001)\n",
      "('loss : ', 54.457509443858569)\n",
      "('accuracy : ', 0.61199999999999999)\n",
      "('loss : ', 53.249030845299885)\n",
      "('accuracy : ', 0.66800000000000004)\n",
      "('loss : ', 53.531665205361115)\n",
      "('accuracy : ', 0.63400000000000001)\n",
      "('loss : ', 52.108025389447207)\n",
      "('accuracy : ', 0.68200000000000005)\n",
      "('loss : ', 52.49835347221574)\n",
      "('accuracy : ', 0.65600000000000003)\n",
      "('loss : ', 50.908993836282534)\n",
      "('accuracy : ', 0.70199999999999996)\n",
      "('loss : ', 51.361323548406418)\n",
      "('accuracy : ', 0.66600000000000004)\n",
      "('loss : ', 49.671776876561651)\n",
      "('accuracy : ', 0.71799999999999997)\n",
      "('loss : ', 50.13571807673847)\n",
      "('accuracy : ', 0.68799999999999994)\n",
      "('loss : ', 48.421180314131959)\n",
      "('accuracy : ', 0.746)\n",
      "('loss : ', 48.849958000835173)\n",
      "('accuracy : ', 0.70799999999999996)\n",
      "('loss : ', 47.186412483175424)\n",
      "('accuracy : ', 0.77800000000000002)\n",
      "('loss : ', 47.544941962741248)\n",
      "('accuracy : ', 0.71799999999999997)\n",
      "('loss : ', 45.999131518906253)\n",
      "('accuracy : ', 0.78200000000000003)\n",
      "('loss : ', 46.269336441940744)\n",
      "('accuracy : ', 0.73199999999999998)\n",
      "('loss : ', 44.889545905486813)\n",
      "('accuracy : ', 0.78000000000000003)\n",
      "('loss : ', 45.070951888137756)\n",
      "('accuracy : ', 0.74399999999999999)\n",
      "('loss : ', 43.880948298276465)\n",
      "('accuracy : ', 0.77600000000000002)\n",
      "('loss : ', 43.98640236450278)\n",
      "('accuracy : ', 0.746)\n",
      "('loss : ', 42.984409993831548)\n",
      "('accuracy : ', 0.77800000000000002)\n",
      "('loss : ', 43.033105712204737)\n",
      "('accuracy : ', 0.746)\n",
      "('loss : ', 42.196054760227497)\n",
      "('accuracy : ', 0.78000000000000003)\n",
      "('loss : ', 42.207390167566771)\n",
      "('accuracy : ', 0.752)\n",
      "('loss : ', 41.498669254187526)\n",
      "('accuracy : ', 0.78400000000000003)\n",
      "('loss : ', 41.490070616148287)\n",
      "('accuracy : ', 0.75800000000000001)\n",
      "('loss : ', 40.868194929622803)\n",
      "('accuracy : ', 0.78600000000000003)\n",
      "('loss : ', 40.858934130274704)\n",
      "('accuracy : ', 0.76000000000000001)\n",
      "('loss : ', 40.285519709623017)\n",
      "('accuracy : ', 0.78400000000000003)\n",
      "('loss : ', 40.308583260745486)\n",
      "('accuracy : ', 0.76800000000000002)\n",
      "('loss : ', 39.755388318751514)\n",
      "('accuracy : ', 0.78400000000000003)\n",
      "('loss : ', 39.881327405324868)\n",
      "('accuracy : ', 0.77600000000000002)\n",
      "('loss : ', 39.334205285997257)\n",
      "('accuracy : ', 0.79400000000000004)\n",
      "('loss : ', 39.710760682686171)\n",
      "('accuracy : ', 0.78200000000000003)\n",
      "('loss : ', 39.153008499385606)\n",
      "('accuracy : ', 0.78800000000000003)\n",
      "('loss : ', 40.039291119783456)\n",
      "('accuracy : ', 0.76800000000000002)\n",
      "('loss : ', 39.351280048474891)\n",
      "('accuracy : ', 0.78400000000000003)\n",
      "('loss : ', 41.027571233453799)\n",
      "('accuracy : ', 0.78400000000000003)\n",
      "('loss : ', 39.772051542823647)\n",
      "('accuracy : ', 0.77600000000000002)\n",
      "('loss : ', 42.212667335084127)\n",
      "('accuracy : ', 0.77600000000000002)\n",
      "('loss : ', 39.7978087330861)\n",
      "('accuracy : ', 0.77600000000000002)\n",
      "('loss : ', 42.601048347111913)\n",
      "('accuracy : ', 0.78800000000000003)\n",
      "('loss : ', 39.134831739674759)\n",
      "('accuracy : ', 0.77800000000000002)\n",
      "('loss : ', 41.995553582164455)\n",
      "('accuracy : ', 0.79600000000000004)\n",
      "('loss : ', 38.138594142732536)\n",
      "('accuracy : ', 0.77400000000000002)\n",
      "('loss : ', 40.986270977935078)\n",
      "('accuracy : ', 0.80200000000000005)\n",
      "('loss : ', 37.13089863051259)\n",
      "('accuracy : ', 0.77400000000000002)\n",
      "('loss : ', 39.947859967888505)\n",
      "('accuracy : ', 0.80000000000000004)\n",
      "('loss : ', 36.196100250277979)\n",
      "('accuracy : ', 0.77800000000000002)\n",
      "('loss : ', 38.912001160577631)\n",
      "('accuracy : ', 0.80000000000000004)\n",
      "('loss : ', 35.301331658866232)\n",
      "('accuracy : ', 0.78200000000000003)\n",
      "('loss : ', 37.794948852872828)\n",
      "('accuracy : ', 0.80000000000000004)\n",
      "('loss : ', 34.392902717384331)\n",
      "('accuracy : ', 0.78600000000000003)\n",
      "('loss : ', 36.5369846810041)\n",
      "('accuracy : ', 0.81200000000000006)\n",
      "('loss : ', 33.434164614801816)\n",
      "('accuracy : ', 0.79200000000000004)\n",
      "('loss : ', 35.133690809703253)\n",
      "('accuracy : ', 0.81200000000000006)\n",
      "('loss : ', 32.407498078522444)\n",
      "('accuracy : ', 0.79800000000000004)\n",
      "('loss : ', 33.616496520652326)\n",
      "('accuracy : ', 0.81200000000000006)\n",
      "('loss : ', 31.309162484786615)\n",
      "('accuracy : ', 0.81599999999999995)\n",
      "('loss : ', 32.03110100129183)\n",
      "('accuracy : ', 0.82199999999999995)\n",
      "('loss : ', 30.148201356394878)\n",
      "('accuracy : ', 0.82999999999999996)\n",
      "('loss : ', 30.425732036658538)\n",
      "('accuracy : ', 0.82999999999999996)\n",
      "('loss : ', 28.945483271412208)\n",
      "('accuracy : ', 0.83999999999999997)\n",
      "('loss : ', 28.843878840531232)\n",
      "('accuracy : ', 0.83399999999999996)\n",
      "('loss : ', 27.728472621601753)\n",
      "('accuracy : ', 0.84999999999999998)\n",
      "('loss : ', 27.318640422207746)\n",
      "('accuracy : ', 0.83399999999999996)\n",
      "('loss : ', 26.523196251242716)\n",
      "('accuracy : ', 0.85799999999999998)\n",
      "('loss : ', 25.870076730929647)\n",
      "('accuracy : ', 0.83799999999999997)\n",
      "('loss : ', 25.348074382133383)\n",
      "('accuracy : ', 0.874)\n",
      "('loss : ', 24.506593521197299)\n",
      "('accuracy : ', 0.84799999999999998)\n",
      "('loss : ', 24.212508450726148)\n",
      "('accuracy : ', 0.88200000000000001)\n",
      "('loss : ', 23.229059791943467)\n",
      "('accuracy : ', 0.86199999999999999)\n",
      "('loss : ', 23.119525376993444)\n",
      "('accuracy : ', 0.88400000000000001)\n",
      "('loss : ', 22.03526673638077)\n",
      "('accuracy : ', 0.86799999999999999)\n",
      "('loss : ', 22.069848176100841)\n",
      "('accuracy : ', 0.89200000000000002)\n",
      "('loss : ', 20.923003280264794)\n",
      "('accuracy : ', 0.872)\n",
      "('loss : ', 21.065091845937847)\n",
      "('accuracy : ', 0.89400000000000002)\n",
      "('loss : ', 19.89128289416292)\n",
      "('accuracy : ', 0.88)\n",
      "('loss : ', 20.1090852662876)\n",
      "('accuracy : ', 0.90600000000000003)\n",
      "('loss : ', 18.940136448939356)\n",
      "('accuracy : ', 0.88400000000000001)\n",
      "('loss : ', 19.207457249757098)\n",
      "('accuracy : ', 0.90800000000000003)\n",
      "('loss : ', 18.069693830658245)\n",
      "('accuracy : ', 0.89400000000000002)\n",
      "('loss : ', 18.366228331142363)\n",
      "('accuracy : ', 0.91600000000000004)\n",
      "('loss : ', 17.279212526738043)\n",
      "('accuracy : ', 0.89600000000000002)\n",
      "('loss : ', 17.590260996415999)\n",
      "('accuracy : ', 0.91600000000000004)\n",
      "('loss : ', 16.566471146962044)\n",
      "('accuracy : ', 0.89800000000000002)\n",
      "('loss : ', 16.882186332242966)\n",
      "('accuracy : ', 0.92000000000000004)\n",
      "('loss : ', 15.927657083210391)\n",
      "('accuracy : ', 0.90000000000000002)\n",
      "('loss : ', 16.242038453066556)\n",
      "('accuracy : ', 0.92400000000000004)\n",
      "('loss : ', 15.357647383642549)\n",
      "('accuracy : ', 0.90200000000000002)\n",
      "('loss : ', 15.667492441816878)\n",
      "('accuracy : ', 0.92600000000000005)\n",
      "('loss : ', 14.850479507173826)\n",
      "('accuracy : ', 0.90200000000000002)\n",
      "('loss : ', 15.154438585488318)\n",
      "('accuracy : ', 0.92800000000000005)\n",
      "('loss : ', 14.399826827275922)\n",
      "('accuracy : ', 0.90400000000000003)\n",
      "('loss : ', 14.69763191279193)\n",
      "('accuracy : ', 0.92800000000000005)\n",
      "('loss : ', 13.999371111835551)\n",
      "('accuracy : ', 0.90600000000000003)\n",
      "('loss : ', 14.291250714662212)\n",
      "('accuracy : ', 0.93000000000000005)\n",
      "('loss : ', 13.643040868840322)\n",
      "('accuracy : ', 0.91000000000000003)\n",
      "('loss : ', 13.92930040955993)\n",
      "('accuracy : ', 0.93400000000000005)\n",
      "('loss : ', 13.325132824186964)\n",
      "('accuracy : ', 0.91800000000000004)\n",
      "('loss : ', 13.605869308949689)\n",
      "('accuracy : ', 0.93400000000000005)\n",
      "('loss : ', 13.040353520710397)\n",
      "('accuracy : ', 0.91800000000000004)\n",
      "('loss : ', 13.31527556840549)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 12.783819112551507)\n",
      "('accuracy : ', 0.91800000000000004)\n",
      "('loss : ', 13.052150588672983)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 12.551043299557737)\n",
      "('accuracy : ', 0.92000000000000004)\n",
      "('loss : ', 12.811495538734677)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 12.337931868295744)\n",
      "('accuracy : ', 0.92200000000000004)\n",
      "('loss : ', 12.588733231801569)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 12.140790724189946)\n",
      "('accuracy : ', 0.92200000000000004)\n",
      "('loss : ', 12.37976277157194)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 11.956344690987066)\n",
      "('accuracy : ', 0.92400000000000004)\n",
      "('loss : ', 12.18101272631317)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 11.781758268583937)\n",
      "('accuracy : ', 0.92400000000000004)\n",
      "('loss : ', 11.989482242929011)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 11.614647816325288)\n",
      "('accuracy : ', 0.92400000000000004)\n",
      "('loss : ', 11.802759099751535)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 11.453076966907537)\n",
      "('accuracy : ', 0.92400000000000004)\n",
      "('loss : ', 11.619008075801172)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 11.295531986876554)\n",
      "('accuracy : ', 0.92800000000000005)\n",
      "('loss : ', 11.436929683223191)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 11.140879158071016)\n",
      "('accuracy : ', 0.93000000000000005)\n",
      "('loss : ', 11.255695442433355)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 10.988310179836882)\n",
      "('accuracy : ', 0.93200000000000005)\n",
      "('loss : ', 11.074869465459088)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 10.837283133202906)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 10.894326562308152)\n",
      "('accuracy : ', 0.93999999999999995)\n",
      "('loss : ', 10.687465825934325)\n",
      "('accuracy : ', 0.93600000000000005)\n",
      "('loss : ', 10.71417507492772)\n",
      "('accuracy : ', 0.93999999999999995)\n",
      "('loss : ', 10.538686190774035)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 10.534689467769523)\n",
      "('accuracy : ', 0.93999999999999995)\n",
      "('loss : ', 10.390891859965189)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 10.356254590422154)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 10.244118876538622)\n",
      "('accuracy : ', 0.93799999999999994)\n",
      "('loss : ', 10.179321235376516)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 10.098468118181513)\n",
      "('accuracy : ', 0.93999999999999995)\n",
      "('loss : ', 10.004371370737511)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.954087438700153)\n",
      "('accuracy : ', 0.94199999999999995)\n",
      "('loss : ', 9.8318910819971599)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.81115759420112)\n",
      "('accuracy : ', 0.94399999999999995)\n",
      "('loss : ', 9.6623494870754527)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.6698804581666398)\n",
      "('accuracy : ', 0.94399999999999995)\n",
      "('loss : ', 9.4961823680288759)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.5304686020825642)\n",
      "('accuracy : ', 0.94799999999999995)\n",
      "('loss : ', 9.3337797481661831)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.3931358510785685)\n",
      "('accuracy : ', 0.94799999999999995)\n",
      "('loss : ', 9.1754769992919947)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.2580888165433208)\n",
      "('accuracy : ', 0.94799999999999995)\n",
      "('loss : ', 9.0215492475234633)\n",
      "('accuracy : ', 0.94599999999999995)\n",
      "('loss : ', 9.1255196243580894)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 8.8722088772351277)\n",
      "('accuracy : ', 0.94799999999999995)\n",
      "('loss : ', 8.9956001105387013)\n",
      "('accuracy : ', 0.95599999999999996)\n",
      "('loss : ', 8.7276058626411945)\n",
      "('accuracy : ', 0.94999999999999996)\n",
      "('loss : ', 8.8684776870379345)\n",
      "('accuracy : ', 0.95799999999999996)\n",
      "('loss : ', 8.5878305441081721)\n",
      "('accuracy : ', 0.94999999999999996)\n",
      "('loss : ', 8.7442729424912731)\n",
      "('accuracy : ', 0.95799999999999996)\n",
      "('loss : ', 8.4529183613987122)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.6230788870288908)\n",
      "('accuracy : ', 0.95799999999999996)\n",
      "('loss : ', 8.3228559914332632)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.5049616166208963)\n",
      "('accuracy : ', 0.95999999999999996)\n",
      "('loss : ', 8.1975883277194352)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.3899620842901097)\n",
      "('accuracy : ', 0.95999999999999996)\n",
      "('loss : ', 8.0770257802803851)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.2780986302590165)\n",
      "('accuracy : ', 0.95999999999999996)\n",
      "('loss : ', 7.9610514560873114)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.1693699352796543)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.8495278833878865)\n",
      "('accuracy : ', 0.95199999999999996)\n",
      "('loss : ', 8.0637581079844551)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.7423030519641944)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 7.9612316825629073)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.6392156418351806)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 7.8617483733279396)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 7.5400993967385332)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 7.7652574973807003)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 7.4447866621761234)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 7.6717020295166627)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 7.3531111509521363)\n",
      "('accuracy : ', 0.95399999999999996)\n",
      "('loss : ', 7.5810202924631973)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 7.2649100244689278)\n",
      "('accuracy : ', 0.95599999999999996)\n",
      "('loss : ', 7.4931473109837965)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 7.1800253892385335)\n",
      "('accuracy : ', 0.95999999999999996)\n",
      "('loss : ', 7.4080158724245306)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 7.098305309002205)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.3255573416545516)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 7.0196044270309983)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.245702277782863)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.9437842834500314)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.1683808958444111)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.8707134009047035)\n",
      "('accuracy : ', 0.96199999999999997)\n",
      "('loss : ', 7.0935234106280252)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.8002672000218709)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 7.0210602932209643)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.7323277948328082)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 6.9509224644694889)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.6667837081317067)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 6.8830414438505585)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.6035295378794228)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 6.8173494674189712)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.5424655982768272)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 6.7537795845773303)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.4834975529643017)\n",
      "('accuracy : ', 0.96399999999999997)\n",
      "('loss : ', 6.6922657403576613)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.4265360528312812)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 6.6327428475994026)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.3714963869914829)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 6.5751468517339751)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.318298152438504)\n",
      "('accuracy : ', 0.96599999999999997)\n",
      "('loss : ', 6.5194147897175521)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.2668649455927072)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.4654848438773111)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.2171240772464857)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.4132963909534517)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.1690063111894737)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.3627900463482945)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.1224456259460469)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.3139077034697522)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.0773789984967621)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 6.2665925680288073)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 6.0337462085130831)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 6.220789187181448)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.9914896614531976)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 6.1764434734687335)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.9505542288012272)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 6.133502723583538)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.9108871037464183)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 6.0919156320684653)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.8724376706675958)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 6.0516323001179284)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.8351573868896995)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 6.0126042397145003)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.7989996752997381)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.9747843733738302)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.7639198265378617)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.9381270298037574)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.7298749096089256)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.9025879358029112)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.6968236898849032)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.8681242047326592)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.6647265535869877)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.8346943218971887)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.6335454379455605)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.8022581271598197)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.6032437663359769)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.7707767951122984)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.5737863877783855)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.7402128130987062)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.545139520270153)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.7105299573779789)\n",
      "('accuracy : ', 0.96799999999999997)\n",
      "('loss : ', 5.5172706974911954)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.6816932676902523)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.4901487184856848)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.6536690204729769)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.4637435999793382)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.6264247009530015)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.4380265310399558)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.5999289743224798)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.4129698298317894)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.5741516561880644)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.3885469022510168)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.5490636824661106)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.3647322022618411)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.5246370788803834)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.3415011937805108)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.5008449302043028)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.3188303139782107)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.4776613493756798)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.2966969378946285)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.4550614465996619)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.2750793442709849)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.433021298543574)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.2539566825265895)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.4115179177168624)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.2333089408151059)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.3905292221193264)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.2131169151072987)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.3700340052316484)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.1933621792557343)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.3500119064138829)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.1740270560039292)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.3304433817696273)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.1550945889081525)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.3113096755263101)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.1365485151448862)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2925927919753413)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.118373239180305)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2742754680095976)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.1005538072811305)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2563411462897642)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.0830758828481422)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2387739490658074)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.0659257225551801)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2215586526746964)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.0490901532775023)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.2046806627309863)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.0325565497939477)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.188125990022562)\n",
      "('accuracy : ', 0.96999999999999997)\n",
      "('loss : ', 5.0163128132476462)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.1718812271197585)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 5.0003473503501681)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.1559335257027659)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9846490533139605)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.1402705746088273)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9692072804975265)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.1248805785976526)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9540118377477373)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.1097522378310378)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9390529604232594)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0948747280602138)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9243212960826011)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0802376815121626)\n",
      "('accuracy : ', 0.97199999999999998)\n",
      "('loss : ', 4.9098078878201852)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0658311684646717)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8955041582333898)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0516456794979181)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8814018940032629)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0376721084091187)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8674932310713945)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0239017357756692)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8537706403952843)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 5.0103262131511563)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8402269142644494)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9969375478777796)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8268551531594159)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9837280884981974)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8136487531357588)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.970690510749125)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8006013937155085)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.95781780411901)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7877070262683237)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9451032589514661)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7749598628648684)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9325404540763671)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7623543655853577)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9201232449503021)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7498852362661808)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.9078457522882637)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7375474066681136)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8957023511685103)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7253360290496556)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8836876605927841)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7132464671297303)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8717965334844333)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7012742874241154)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8600240471070864)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6894152509405229)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8483654938871972)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6776653052176318)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8368163726237192)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6660205766938292)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8253723800692443)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6544773633918144)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8140294028666712)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6430321279058813)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.8027835098264386)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6316814906786918)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7916309445295981)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6204222235554742)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7805681182425772)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.6092512436033743)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7695916031299017)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5981656071846206)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7586981257516499)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5871625042723361)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7478845608329276)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5762392529983824)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7371479252931472)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5653932944230871)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7264853725232534)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5546221875169239)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7158941868996731)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5439236043449585)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.7053717785241052)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5332953254449109)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6949156781787593)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5227352353903463)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6845235324871251)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5122413185307462)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6741930992707115)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.5018116549006191)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6639222430927045)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4914444162901788)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6537089309798336)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4811378624703089)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.643551228314049)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4708903375651357)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.633447294886281)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4607002665656594)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.623395381104606)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.450566151978137)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6133938243496431)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.440486570601335)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.6034410454702765)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4304601704270823)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5935355454133999)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4204856676586584)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5836759019811888)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4105618438418945)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5738607667102107)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.4006875431041994)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5640888618667264)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3908616694967471)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5543589775528517)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.381083184435524)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5446699689184964)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3713511042369717)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.5350207534743934)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3616644977442274)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.525410308501586)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3520224840402246)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.5158376685531447)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3424242302440099)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.5063019230439885)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3328689493867891)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4968022139250046)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3233558983645652)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4873377334377924)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3138843759641787)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.477907721946595)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.3044537209598319)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4685114658442142)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2950633102773459)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4591482955286681)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.28571255722344)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4498175834479863)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2764009097775553)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.440518742210064)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2671278489438338)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4312512227552237)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2578928871609651)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.4220145125890227)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2486955667677835)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.41280813407288)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2395354585225125)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.403631642770506)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.230412160173799)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3944846258480492)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2213252950816429)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3853667005260082)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2122745108864788)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3762775125811784)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.2032594782248101)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3672167348968527)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1942798894896836)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3581840660597262)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1853354576347002)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3491792290020141)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1764259150200163)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3402019696873833)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1675510122989854)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3312520558392125)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1587105173441872)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.322329275710219)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1499042142116895)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.3134334368919252)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.141131902142229)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.304564365163178)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1323933945983393)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2957219033763963)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1236885183363263)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2869059103807876)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1150171125120369)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2781162599813793)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.1063790278195524)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2693528399331724)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.0977741256618359)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2606155509694759)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.0892022773524461)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2519043058636106)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.0806633633474796)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2432190285232654)\n",
      "('accuracy : ', 0.97399999999999998)\n",
      "('loss : ', 4.072157272506951)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2345596531167722)\n",
      "('accuracy : ', 0.97599999999999998)\n",
      "('loss : ', 4.0636839013848558)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2259261232306731)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.0552431535471269)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2173183910577396)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.0468349389167635)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.2087364166150323)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.0384591731454709)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.2001801669912631)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.030115777011166)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.19164961562287)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.0218046758405848)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.183144741598273)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.0135257989565076)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.1746655289898342)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 4.005279079148913)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.166211966212777)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 3.9970644521694245)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.1577840454107875)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 3.9888818562486232)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.1493817618675948)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 3.9807312316354557)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.1410051134441828)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 3.9726125201584059)\n",
      "('accuracy : ', 0.97999999999999998)\n",
      "('loss : ', 4.1326541000410133)\n",
      "('accuracy : ', 0.97799999999999998)\n",
      "('loss : ', 3.9645256648076779)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqWIMfkmqGINfkirG4JekijH4Jali/j8o6QCn0ompqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba1695b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEKCAYAAADzQPVvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba6984790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "L_monitor = []\n",
    "acc_monitor = []\n",
    "for epoch in range(nb_epochs):\n",
    "    # forward pass\n",
    "    e1 = np.dot(X, W1) + b1\n",
    "    h1 = g(e1)\n",
    "    e2 = np.dot(h1, W2) + b2\n",
    "    h2 = g(e2)\n",
    "    e3 = np.dot(h2, W3) + b3\n",
    "    o = g(e3)\n",
    "    acc = ((o[:, 0]>0.5)==y).mean()\n",
    "    acc_monitor.append(acc)\n",
    "    print(\"accuracy : \", acc)\n",
    "    L = 0.5 * ((y[:, np.newaxis] - o)**2)\n",
    "    print(\"loss : \", L.sum())\n",
    "    L_monitor.append(L.sum())\n",
    "    # backward pass\n",
    "    d_o = (o - y[:, np.newaxis])\n",
    "    d_e3 = d_o * o * (1 - o) # equation 2 + using the property of the sigmoid described just above\n",
    "    d_h2 = np.dot(d_e3, W3.T) # equation 1\n",
    "    d_e2 = d_h2 * h2 * (1 - h2) # equation 2 + + using the property of the sigmoid described just above\n",
    "    d_h1 = np.dot(d_e2, W2.T) # equation 1\n",
    "    d_e1 = d_h1 * h1 * (1 - h1)\n",
    "    # gradients\n",
    "    d_W3 = np.dot(h2.T, d_e3)\n",
    "    d_W2 = np.dot(h1.T, d_e2)\n",
    "    d_W1 = np.dot(X.T, d_e1)\n",
    "    \n",
    "    d_b3 = d_e3.sum(axis=0)\n",
    "    d_b2 = d_e2.sum(axis=0)\n",
    "    d_b1 = d_e1.sum(axis=0)\n",
    "    # update\n",
    "\n",
    "    W3 -= alpha * d_W3\n",
    "    W2 -= alpha * d_W2\n",
    "    W1 -= alpha * d_W1\n",
    "    b3 -= alpha * d_b3\n",
    "    b2 -= alpha * d_b2\n",
    "    b1 -= alpha * d_b1\n",
    "\n",
    "plt.plot(L_monitor)\n",
    "plt.title(\"loss\")\n",
    "plt.show()\n",
    "plt.plot(acc_monitor)\n",
    "plt.title(\"acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet(BaseEstimator):\n",
    "    \n",
    "    def predict(self, X):\n",
    "        e1 = np.dot(X, W1) + b1\n",
    "        h1 = g(e1)\n",
    "        e2 = np.dot(h1, W2) + b2\n",
    "        h2 = g(e2)\n",
    "        e3 = np.dot(h2, W3) + b3\n",
    "        o = g(e3)\n",
    "        y = 1 * (o > 0.5)\n",
    "        return y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfs9hizwldgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba16641d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here we used **squared error** as a loss function for its simplicity but we note that for classification it is rather the [**cross entropy**](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) (or logloss) loss function which is used in general along with a [**softmax**](https://en.wikipedia.org/wiki/Softmax_function) activation function in the output layer rather than **sigmoid**. \n",
    "\n",
    "The [**softmax**](https://en.wikipedia.org/wiki/Softmax_function) activation function in the output layer converts a set of predictions (one prediction per class) to probabilties, corresponding to a **multinomial distribution**, so it is a generalization of **sigmoid** for multi-class.  \n",
    "\n",
    "**Cross entropy** penalizes bad predictions more heavily than **squared error**, say for an example the true class is the j-th one and $p_j$ is the predicted probability of the class j (obtained from softmax), then **cross entropy** is for this case : $-log p_j$ which goes to infinity as $p_j$ goes to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural  networks libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nolearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get introduced to one of the neural network libraries and introduce at the same time new concepts.\n",
    "\n",
    "[**Nolearn**](https://github.com/dnouri/nolearn/) is a high level neural network library, based on [**Lasagne**](https://github.com/Lasagne/Lasagne), which provides a [scikit-learn](scikit-learn.org) like **NeuralNet** class with fit, predict etc. [**Lasagne**](https://github.com/Lasagne/Lasagne) itself is based on [**theano**](https://github.com/Theano/).\n",
    "\n",
    "[**theano**](https://github.com/Theano/) is not  a library for neural networks only, it is a library which allow you\n",
    "to manipulate a symbolic computational graph. \n",
    "\n",
    "For instance it allows you to write\n",
    "the loss function as a symbolic variable and then get the gradients with respect to the parameters automatically, after that you can define functions which do some \n",
    "computations based on these symbolic variables, like for instance updating the parameters of your model based on the gradients of the loss function with respect to the parameters. These functions are compiled to a fast C code or a CUDA code if you have an NVIDIA GPU card. \n",
    "\n",
    "There are a lot of high level libraries for neural networks which uses theano and [**Lasagne**](https://github.com/Lasagne/Lasagne)is one of them. [**Nolearn**](https://github.com/dnouri/nolearn/) provides us a class with a scikit-learn interface based on [**Lasagne**](https://github.com/Lasagne/Lasagne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\" # to tell theano to use a GPU :)\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train  a **feedforward neural network** with **nolearn** for classifying insects !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load(\"train_64x64.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = data[\"X\"], data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20348, 64, 64, 3)\n",
      "(20348,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X are the examples and y the labels.\n",
    "We see that X is a 4D tensor where :\n",
    "\n",
    "- the first dimension is the examples\n",
    "- the second is the height\n",
    "- the third is the width \n",
    "- the fourth (and last) are color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20348, 12288)\n"
     ]
    }
   ],
   "source": [
    "X = X.astype(np.float32) # For GPUs, theano excpects float32 inputs\n",
    "X_vectorized = X.reshape((X.shape[0], -1))\n",
    "print(X_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "from lasagne import layers, nonlinearities, updates, init, objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=100,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.sigmoid,\n",
    "    hidden1_W=init.Uniform((-0.01, 0.01)),\n",
    "    \n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.Uniform((-0.01, 0.01)),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # Optimization method:\n",
    "    update=updates.sgd, # The optimization algorithm is stochastic gradient descent (SGD)\n",
    "    update_learning_rate=0.1, # The global learning rate of all the weights for SGD\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=300,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 1230718 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input     12288\n",
      "  1  hidden1     100\n",
      "  2  output       18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    train_acc    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.47719\u001b[0m       \u001b[32m2.49992\u001b[0m      0.99091      0.27833      0.28757  0.96s\n",
      "      2       \u001b[36m2.47547\u001b[0m       \u001b[32m2.49970\u001b[0m      0.99030      0.27587      0.28757  0.96s\n",
      "      3       \u001b[36m2.47537\u001b[0m       \u001b[32m2.49970\u001b[0m      0.99027      0.27581      0.28757  0.96s\n",
      "      4       \u001b[36m2.47537\u001b[0m       2.49971      0.99026      0.27581      0.28757  0.96s\n",
      "      5       \u001b[36m2.47503\u001b[0m       \u001b[32m2.49810\u001b[0m      0.99076      0.27581      0.28757  0.96s\n",
      "      6       \u001b[36m2.47456\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "      7       2.47456       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "      8       2.47456       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "      9       2.47456       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     10       2.47456       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     11       \u001b[36m2.47456\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     12       \u001b[36m2.47456\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     13       \u001b[36m2.47455\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     14       \u001b[36m2.47455\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     15       \u001b[36m2.47455\u001b[0m       2.49814      0.99056      0.27581      0.28757  0.96s\n",
      "     16       \u001b[36m2.47455\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     17       \u001b[36m2.47455\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     18       \u001b[36m2.47454\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     19       \u001b[36m2.47454\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     20       \u001b[36m2.47454\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     21       \u001b[36m2.47454\u001b[0m       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     22       \u001b[36m2.47454\u001b[0m       2.49815      0.99055      0.27581      0.28757  0.96s\n",
      "     23       2.47454       2.49815      0.99055      0.27581      0.28757  0.96s\n",
      "     24       \u001b[36m2.47453\u001b[0m       2.49815      0.99055      0.27581      0.28757  0.96s\n",
      "     25       \u001b[36m2.47453\u001b[0m       2.49815      0.99055      0.27581      0.28757  0.96s\n",
      "     26       \u001b[36m2.47453\u001b[0m       2.49815      0.99055      0.27581      0.28757  0.96s\n",
      "     27       \u001b[36m2.47453\u001b[0m       2.49815      0.99054      0.27581      0.28757  0.96s\n",
      "     28       \u001b[36m2.47453\u001b[0m       2.49815      0.99054      0.27581      0.28757  0.96s\n",
      "     29       \u001b[36m2.47389\u001b[0m       \u001b[32m2.49660\u001b[0m      0.99090      0.27888      0.28757  0.96s\n",
      "     30       \u001b[36m2.47376\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     31       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     32       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     33       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     34       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     35       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     36       \u001b[36m2.47375\u001b[0m       2.49660      0.99085      0.27980      0.28757  0.96s\n",
      "     37       \u001b[36m2.47374\u001b[0m       2.49660      0.99084      0.27980      0.28757  0.96s\n",
      "     38       2.47376       \u001b[32m2.49658\u001b[0m      0.99086      0.27980      0.28757  0.96s\n",
      "     39       2.47377       \u001b[32m2.49658\u001b[0m      0.99086      0.27980      0.28757  0.96s\n",
      "     40       2.47377       \u001b[32m2.49658\u001b[0m      0.99086      0.27980      0.28757  0.96s\n",
      "     41       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     42       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     43       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     44       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     45       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     46       2.47377       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     47       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     48       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     49       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     50       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     51       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     52       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     53       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     54       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     55       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     56       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     57       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     58       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     59       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     60       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     61       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     62       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     63       2.47375       2.49658      0.99085      0.27980      0.28757  0.96s\n",
      "     64       2.47377       \u001b[32m2.49657\u001b[0m      0.99087      0.27912      0.28757  0.96s\n",
      "     65       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     66       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     67       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     68       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     69       2.47375       2.49658      0.99085      0.27980      0.28757  0.96s\n",
      "     70       2.47375       2.49658      0.99085      0.27980      0.28757  0.96s\n",
      "     71       2.47375       2.49658      0.99085      0.27980      0.28757  0.96s\n",
      "     72       2.47380       2.49658      0.99088      0.27980      0.28757  0.96s\n",
      "     73       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     74       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     75       2.47376       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     76       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     77       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     78       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     79       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     80       2.47375       2.49658      0.99086      0.27980      0.28757  0.96s\n",
      "     81       2.47375       2.49658      0.99085      0.27980      0.28757  0.96s\n",
      "     82       2.47448       2.49814      0.99053      0.27581      0.28757  0.96s\n",
      "     83       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     84       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     85       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     86       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     87       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     88       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     89       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     90       2.47453       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     91       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     92       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     93       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     94       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     95       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     96       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     97       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     98       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "     99       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "    100       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "    101       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "    102       2.47452       2.49814      0.99055      0.27581      0.28757  0.96s\n",
      "    103       2.47452       2.49814      0.99054      0.27581      0.28757  0.96s\n",
      "    104       2.47405       2.49659      0.99097      0.27771      0.28757  0.96s\n",
      "    105       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    106       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    107       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    108       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    109       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    110       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    111       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    112       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    113       2.47375       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    114       2.47374       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    115       2.47374       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    116       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    117       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    118       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    119       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    120       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    121       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    122       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    123       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    124       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    125       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    126       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    127       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    128       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    129       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    130       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    131       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    132       \u001b[36m2.47374\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    133       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    134       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    135       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    136       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    137       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    138       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    139       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    140       \u001b[36m2.47373\u001b[0m       2.49659      0.99085      0.27980      0.28757  0.96s\n",
      "    141       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    142       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    143       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    144       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    145       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    146       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    147       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    148       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    149       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    150       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    151       \u001b[36m2.47373\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    152       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    153       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    154       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    155       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    156       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    157       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    158       2.47377       2.49659      0.99086      0.27980      0.28757  0.96s\n",
      "    159       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    160       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    161       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    162       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    163       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    164       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    165       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    166       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    167       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    168       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    169       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    170       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    171       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    172       2.47373       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    173       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    174       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    175       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    176       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    177       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    178       2.47372       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    179       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    180       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    181       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    182       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    183       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    184       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    185       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    186       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    187       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    188       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    189       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    190       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    191       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    192       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    193       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    194       \u001b[36m2.47372\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    195       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    196       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    197       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    198       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    199       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    200       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    201       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    202       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    203       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27980      0.28757  0.96s\n",
      "    204       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27986      0.28757  0.96s\n",
      "    205       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27986      0.28757  0.96s\n",
      "    206       \u001b[36m2.47371\u001b[0m       2.49659      0.99084      0.27986      0.28757  0.96s\n",
      "    207       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    208       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    209       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    210       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    211       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    212       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    213       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    214       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    215       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    216       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    217       \u001b[36m2.47371\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    218       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    219       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    220       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    221       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    222       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    223       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    224       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    225       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    226       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    227       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    228       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    229       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    230       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    231       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    232       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    233       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    234       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    235       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    236       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    237       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    238       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    239       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    240       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    241       \u001b[36m2.47370\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    242       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    243       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    244       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    245       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    246       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    247       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    248       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    249       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    250       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    251       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    252       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    253       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    254       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    255       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    256       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    257       \u001b[36m2.47369\u001b[0m       2.49659      0.99083      0.27986      0.28757  0.96s\n",
      "    258       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    259       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    260       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    261       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    262       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    263       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    264       \u001b[36m2.47369\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    265       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    266       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    267       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    268       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    269       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    270       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    271       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    272       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    273       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    274       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    275       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    276       \u001b[36m2.47368\u001b[0m       2.49659      0.99082      0.27986      0.28757  0.96s\n",
      "    277       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    278       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    279       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    280       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    281       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    282       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    283       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    284       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    285       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    286       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    287       \u001b[36m2.47368\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    288       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    289       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    290       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    291       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    292       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    293       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    294       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    295       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    296       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    297       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    298       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    299       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n",
      "    300       \u001b[36m2.47367\u001b[0m       2.49660      0.99082      0.27986      0.28757  0.96s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f4beb480250>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f4beb48f750>,\n",
       "     custom_score=None,\n",
       "     hidden1_W=<lasagne.init.Uniform object at 0x7f4beb48f6d0>,\n",
       "     hidden1_nonlinearity=<function sigmoid at 0x7f4beb855488>,\n",
       "     hidden1_num_units=100, input_shape=(None, 12288),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=300, more_params={},\n",
       "     objective=<function objective at 0x7f4beb4816e0>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f4beb811230>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f4beb487ab8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f4beb487b00>],\n",
       "     output_W=<lasagne.init.Uniform object at 0x7f4beb48f710>,\n",
       "     output_nonlinearity=<function softmax at 0x7f4beb855500>,\n",
       "     output_num_units=18, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f4beb480290>,\n",
       "     update=<function sgd at 0x7f4beb811758>, update_learning_rate=0.1,\n",
       "     use_label_encoder=True, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_vectorized, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training seems to be slow, we are evennot capable of fitting training data. What is the reason behind this slowness ?\n",
    "First, let's check scaling of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 255.0)\n"
     ]
    }
   ],
   "source": [
    "print(X_vectorized.min(), X_vectorized.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because input have large values the values of the hidden layer before applying sigmoid have a big magnitude, so the values after applying sigmoid are mostly either close to 0 or close to 1, so they are **saturated**. One way to prevent this is to rescale the inputs to a range which is **compatible** with the range of the activation function, here the sigmoid. \n",
    "\n",
    "One way to do that is to force the features to be between the min and the max, for this specific case we can just divide by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=100,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.sigmoid,\n",
    "    hidden1_W=init.Uniform((-0.01, 0.01)),\n",
    "    \n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.Uniform((-0.01, 0.01)),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # Optimization method:\n",
    "    update=updates.sgd, # The optimization algorithm is stochastic gradient descent (SGD)\n",
    "    update_learning_rate=0.1, # The global learning rate of all the parameters for SGD,\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=300,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized/255., y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the difference between the two. Notice also that in the first case we are **underfitting** and in the second case we are **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways of preprocessing the data, in (Efficient Backprop, Yann Lecun, 1998), they advice to make the average of each input feature close to zero, to rescale input features to the same scale and make the input features uncorrelated. Making average of each input close to zero and rescaling them to the same scale can be implemetend using [**StandardScaler()**](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) , linear decorrelation can be implemented by a [**PCA**](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than that, in (Efficient Backprop, Yann Lecun, 1998), they advice to make the average of each layer to be close to zero, and thus this make classical **sigmoid** not **recommanded** because it is not centered around zero, **tanh** which is a rescaled version of sigmoid, is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4ba1822590>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvohIHVHoi4jUEYW+iEgdUeiLiNSR/w99OYtBRkoNaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba14fa890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.arange(-10, 10, 0.1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(a, np.tanh(a))\n",
    "plt.title(\"tanh activation function\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(a, 1./(1. + np.exp(-a)))\n",
    "plt.title(\"sigmoid activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=100,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.tanh,\n",
    "    hidden1_W=init.Uniform((-0.01, 0.01)),\n",
    "    \n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.Uniform((-0.01, 0.01)),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # Optimization method:\n",
    "    update=updates.sgd, # The optimization algorithm is stochastic gradient descent (SGD)\n",
    "    update_learning_rate=0.1, # The global learning rate of all the parameters for SGD,\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=30,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_vectorized_rescaled = StandardScaler().fit_transform(X_vectorized)\n",
    "net.fit(X_vectorized_rescaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how much training is faster now ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent and its variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The parameter **update** describe the optimization method used, the optimization methods are available in the module **updates** of **lasagne**. \n",
    "\n",
    "All of them use the **learning_rate** parameter which you can set by using **update_learning_rate=some_value**, some of them use the **momentum** parameter, which you can set by using **update_momentum=some_value**, some methods have their own additional hyper-parameters. \n",
    "\n",
    "For a \"live\" comparison between some training methods see this link http://cs.stanford.edu/people/karpathy/convnetjs/demo/trainers.html. \n",
    "\n",
    "Some methods:\n",
    "\n",
    "- [**updates.sgd**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.sgd) , it is stochastic gradient descent, use only the learning_rate as a global learning rate\n",
    "- [**updates.momentum**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.momentum), use **learning_rate** and **momentum** parameters\n",
    "- [**updates.nesterov_momentum**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.nesterov_momentum) , use **learning_rate** and **momentum** parameters\n",
    "- [**updates.adagrad**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.adagrad) , use only the learning_rate parameter as a global learning rate but is at the same time adaptive and it computes a learning rate for each parameter, learning rate decaying is not needed it is also done automatically.\n",
    "- [**updates.adadelta**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.adadelta), it is based on **adagrad** but proposes to fix some issues that **adadelta** has, the paper states that it is not very sensitive to its hyper-parameters.\n",
    "- [**updates.adam**](http://lasagne.readthedocs.org/en/latest/modules/updates.html#lasagne.updates.adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/s25RsOr.gif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=100,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.tanh,\n",
    "    hidden1_W=init.Uniform((-0.01, 0.01)),\n",
    "    \n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.Uniform((-0.01, 0.01)),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # Optimization method:\n",
    "    update=updates.adadelta, # The optimization algorithm is Adadelta\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=30,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized_rescaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience adadelta/adagrad are good to start with, they are usually behaving well, but as many\n",
    "authors say, carefeully tuning classical stochastic gradient descent with momentum  works\n",
    "better in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the activation functions are available in the module **nonlinearities** of **lasagne**.\n",
    "\n",
    "You can set the activation function for a given layer by **layername_nonlinearity=activation_function**\n",
    "\n",
    "Complete list : http://lasagne.readthedocs.org/en/latest/modules/nonlinearities.html\n",
    "\n",
    "- **sigmoid** : not recommanded, except for few cases, it may be useful as output non-linearities for auto-encoders with binary inputs.\n",
    "- **tanh** : rescaled version of sigmoid which is centered around zero, better than sigmoid.\n",
    "- **rectify** : Rectified linear units : $max(0, x)$, most widely used right now because they have shown to speed up training and they work well with big models. Their problem is that they are known to \"kill\" a large number of units (at some some units get always value of zero regardless of inputs, and thus will prevent the weights connected to these units to not be updated).\n",
    "- **LeakyRectify** : $max(\\alpha x, x)$ where $\\alpha > 0$ is a hyper-parameter, it is meant to reduce the dead units problem occuring with rectified linear units.\n",
    "* **leaky_rectify** : **LeakyRectify** with $\\alpha=0.01$\n",
    "* **softmax** : Used in output layers for multi-class classification problems\n",
    "\n",
    "Note that the default activation function is **rectify**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAKCCAYAAABBBWgoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiSpwVgASpIkNRgLQEmSpAbz/wEM8IJh8qbcmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba1865950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "a = np.arange(-10, 10, 0.01)\n",
    "plt.subplot(2, 2, 1)\n",
    "s = 1./(1 + np.exp(-a))\n",
    "plt.plot(a, s, color='b', label=\"f\")\n",
    "plt.plot(a, s * (1 - s), color='r', label=\"f'\")\n",
    "plt.legend()\n",
    "plt.title(\"sigmoid activation function\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(a, np.tanh(a), color='b', label=\"f\")\n",
    "plt.plot(a, 1 - np.tanh(a)**2, color='r', label=\"f'\")\n",
    "plt.legend()\n",
    "plt.title(\"tanh activation function\")\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(a, np.maximum(0, a), c='b', label=\"f\")\n",
    "plt.plot(a, a>0, c='r', label=\"f'\")\n",
    "plt.legend()\n",
    "plt.title(\"rectify activation function\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(a, np.maximum(0.01*a, a), c='b', label=\"f\")\n",
    "plt.plot(a, (a>0)*1 + (a<0)*0.01, c='r', label=\"f'\")\n",
    "plt.legend()\n",
    "plt.title(\"leaky_rectify activation function\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also implement yymour own activation function, you just create a function which takes an input x and transforms it accordingly, and then you assign this function to **layername_nonlinearity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight initialization is very important as it will determine the behavior of training, with a bad initialization learning will not behave correctly. \n",
    "\n",
    "Initialization schemes are available in the model **init** of **lasagne**, they can be set by **layername_W=InitializationProcedureName(params)** for weights and **layername_b=InitializationProcedureName(params)** for biases (default to 0).\n",
    "\n",
    "Weight initialization should be chosen such that it does not kill the gradients. For instance if we use **tanh** and the input of **tanh** is a linear combination between units in previous layer and weights and there are a lot of units , the scale of the input of the **tanh** will be big, so after applying **tanh** it will be saturated. So one would rescale the weights proportionally to the number of units.\n",
    "\n",
    "This first kind of initilization is called [**He**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.He), it comes with a uniform [**HeUniform**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.HeUniform) and a normal [**HeNormal**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.HeNormal) version.\n",
    "\n",
    "The most popular is [**GlorotUniform**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.GlorotUniform) which works\n",
    "usually well. For a given weight matrix, the proposed range by this scheme is not only based on the number \n",
    "of input units but also on the number output units : $$W^{(l)} \\sim Unif[-\\frac{\\sqrt{6}}{-\\sqrt{n^{(l)}+n^{(l+1)}}}, \\frac{\\sqrt{6}}{-\\sqrt{n^{(l)}+n^{(l+1)}}}]$$ where $n^{(l)}$ are the number units in layer ${(l)}$. It has also a normal distributed version with the same standard deviation than the uniform distributed version [**GlorotNormal**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.GlorotNormal).\n",
    "\n",
    "Another scheme worth to try is [**Orthogonal**](http://lasagne.readthedocs.org/en/latest/modules/init.html#lasagne.init.GlorotUniform) initialization, which initializes weight matrices by a random semi-orthogonal matrix.\n",
    "\n",
    "**Remember** to use **gain='relu'** if you use **rectified linear units** in any of these initialization procedures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('hidden2', layers.DenseLayer),\n",
    "            ('hidden3', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=500,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.rectify,\n",
    "    hidden1_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    hidden2_num_units=500,  # number of units in 2nd hidden layer\n",
    "    hidden2_nonlinearity=nonlinearities.rectify,\n",
    "    hidden2_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    hidden3_num_units=500,  # number of units in 3rd hidden layer\n",
    "    hidden3_nonlinearity=nonlinearities.rectify,\n",
    "    hidden3_W=init.GlorotUniform(gain='relu'),\n",
    "\n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.GlorotUniform(),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # Optimization method:\n",
    "    update=updates.adadelta, # The optimization algorithm is Adadelta\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=15,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized_rescaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only saw about how to optimize neural networks to fit  training data, so we only dealt with **underfitting** problems occuring with neural networks. But the goal of machine learning is not to fit training data, the goal is to generalize to unseen inputs and thus to have low error on test data. \n",
    "\n",
    "As far as we fix the underfitting problem and train our neural network nicely, we can quickly observe overfitting, observed clearly by learning curves :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss = np.array([i[\"train_accuracy\"] for i in net.train_history_])\n",
    "valid_loss = np.array([i[\"valid_accuracy\"] for i in net.train_history_])\n",
    "plt.plot(train_loss, c=\"b\", label=\"train accuracy\", linewidth=3)\n",
    "plt.plot(valid_loss, c=\"g\", label=\"valid accuracy\", linewidth=3)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to regularize is to get more data ! \n",
    "\n",
    "Unfortunately it is not always possible to gather new data \n",
    "(specially labeled ones) because it is costly. One way to cheaply gather new data is to exploit some properties\n",
    "of the data distribution to generate artificially new data. For instance, if we have images, a cheap way to generate\n",
    "data is to apply affine transformations on the images like **scaling**, **rotations** and \n",
    "**translations**. But we will go back to this later.\n",
    "\n",
    "We will first talk about classical regularization techniques used in neural networks and see how to use them\n",
    "in **Nolearn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to regularize a neural network is to constrain its capacity. Two forms of weight decay penalties are **L1** and **L2**, **L1** penalizes the absolute value of the weights while **L2** penalizes the squared value of the weights. **L1** tends to give sparse values to the weights (that is, exact zero values to a subset of weights).\n",
    "\n",
    "For both **L1** and **L2** there is a hyper-parameter $\\lambda$, called the **regularization coeficient**, it is controlling how much you give importance to regularization compared with fitting the training data (the objective function), it must be a positive real number and it is usually very small, e.g 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne.base import objective\n",
    "from lasagne.objectives import aggregate\n",
    "from lasagne.regularization import regularize_layer_params, l2, l1\n",
    "\n",
    "lambda_regularization = 0.08\n",
    "\n",
    "def objective_with_L2(layers,\n",
    "                      loss_function,\n",
    "                      target,\n",
    "                      aggregate=aggregate,\n",
    "                      deterministic=False,\n",
    "                      get_output_kw=None):\n",
    "    reg = regularize_layer_params([layers[\"hidden1\"], layers[\"hidden2\"], layers[\"hidden3\"]], l2)\n",
    "    loss = objective(layers, loss_function, target, aggregate, deterministic, get_output_kw)\n",
    "    \n",
    "    if deterministic is False:\n",
    "        return loss + reg * lambda_regularization\n",
    "    else:\n",
    "        return loss\n",
    "\n",
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('hidden2', layers.DenseLayer),\n",
    "            ('hidden3', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=500,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.rectify,\n",
    "    hidden1_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    hidden2_num_units=500,  # number of units in 2nd hidden layer\n",
    "    hidden2_nonlinearity=nonlinearities.rectify,\n",
    "    hidden2_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    hidden3_num_units=500,  # number of units in 3rd hidden layer\n",
    "    hidden3_nonlinearity=nonlinearities.rectify,\n",
    "    hidden3_W=init.GlorotUniform(gain='relu'),\n",
    "\n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.GlorotUniform(),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    \n",
    "    # objective function\n",
    "    objective=objective_with_L2,\n",
    "    # Optimization method:\n",
    "    update=updates.adadelta, # The optimization algorithm is Adadelta\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized_rescaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss = np.array([i[\"train_accuracy\"] for i in net.train_history_])\n",
    "valid_loss = np.array([i[\"valid_accuracy\"] for i in net.train_history_])\n",
    "plt.plot(train_loss, c=\"b\", label=\"train accuracy\", linewidth=3)\n",
    "plt.plot(valid_loss, c=\"g\", label=\"valid accuracy\", linewidth=3)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another cheap ad simple way to regularize is to use **dropout**. **Dropout** as a way of preventing\n",
    "units of co-adapting by randomly **dropping** units in each layer, that is setting their values to 0\n",
    "with a certain probability, with $p=0.5$ usually. \n",
    "By applying **dropout**  for a given layer, we force units to be useful as themselves to the next\n",
    "layer units. **Dropout** can also be seen as a way to create an ensemble of neural networks with\n",
    "shared parameters. Thus, at test time, to approximate averaging of this ensemble with multiply\n",
    "the units by **p**.\n",
    "\n",
    "**Dropout** are a kind of layers in **lasagne**, they take the previous layer, randomly zero-out their\n",
    "units with the given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('hidden2', layers.DenseLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('hidden3', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=1500,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.rectify,\n",
    "    hidden1_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    dropout1_p=0.5,\n",
    "    \n",
    "    hidden2_num_units=1500,  # number of units in 2nd hidden layer\n",
    "    hidden2_nonlinearity=nonlinearities.rectify,\n",
    "    hidden2_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    dropout2_p=0.5,\n",
    "    \n",
    "    hidden3_num_units=1500,  # number of units in 3rd hidden layer\n",
    "    hidden3_nonlinearity=nonlinearities.rectify,\n",
    "    hidden3_W=init.GlorotUniform(gain='relu'),\n",
    "\n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.GlorotUniform(),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    \n",
    "    # Optimization method:\n",
    "    update=updates.adadelta, # The optimization algorithm is Adadelta\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized_rescaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common way of regularizing is to use **early stopping**. As said above, in machine learning we are interested in validation error not in training error so usually we monitor the validation error and stop when it starts increasing. Early stopping is an attempt to automatize this process. It is done by monitoring validation error and memorizing the best model so far in terms of validation error and it stops when the validation error is not decreasing after a certain number epochs determined by a **patience** parameter. The chosen model after stopping is the one with the best error on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do that in Nolearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "\n",
    "    def __init__(self, patience=100, criterion='valid_loss',\n",
    "                 criterion_smaller_is_better=True):\n",
    "        self.patience = patience\n",
    "        if criterion_smaller_is_better is True:\n",
    "            self.best_valid = np.inf\n",
    "        else:\n",
    "            self.best_valid = -np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "        self.criterion = criterion\n",
    "        self.criterion_smaller_is_better = criterion_smaller_is_better\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1][self.criterion]\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if self.criterion_smaller_is_better:\n",
    "            cond = current_valid < self.best_valid\n",
    "        else:\n",
    "            cond = current_valid > self.best_valid\n",
    "        if cond:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            if nn.verbose:\n",
    "                print(\"Early stopping.\")\n",
    "                print(\"Best {:s} was {:.6f} at epoch {}.\".format(\n",
    "                    self.criterion, self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_weights_from(self.best_weights)\n",
    "            if nn.verbose:\n",
    "                print(\"Weights set.\")\n",
    "            raise StopIteration()\n",
    "\n",
    "    def load_best_weights(self, nn, train_history):\n",
    "        nn.load_weights_from(self.best_weights)\n",
    "        \n",
    "net = NeuralNet(\n",
    "    # Define the architecture here\n",
    "    layers=[\n",
    "            ('input', layers.InputLayer), \n",
    "            ('hidden1', layers.DenseLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('hidden2', layers.DenseLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('hidden3', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "    ],\n",
    "    # Layers parameters:\n",
    "    input_shape=(None, X_vectorized.shape[1]), # Number of input features\n",
    "    \n",
    "    hidden1_num_units=1500,  # number of units in 1st hidden layer\n",
    "    hidden1_nonlinearity=nonlinearities.rectify,\n",
    "    hidden1_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    dropout1_p=0.5,\n",
    "    \n",
    "    hidden2_num_units=1500,  # number of units in 2nd hidden layer\n",
    "    hidden2_nonlinearity=nonlinearities.rectify,\n",
    "    hidden2_W=init.GlorotUniform(gain='relu'),\n",
    "    \n",
    "    dropout2_p=0.5,\n",
    "    \n",
    "    hidden3_num_units=1500,  # number of units in 3rd hidden layer\n",
    "    hidden3_nonlinearity=nonlinearities.rectify,\n",
    "    hidden3_W=init.GlorotUniform(gain='relu'),\n",
    "\n",
    "    output_num_units=18,  # 18 classes    \n",
    "    output_W=init.GlorotUniform(),\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    \n",
    "    # Optimization method:\n",
    "    update=updates.adadelta, # The optimization algorithm is Adadelta\n",
    "    batch_iterator_train=BatchIterator(batch_size=100), # mini-batch size\n",
    "    \n",
    "    use_label_encoder=True, # Converts labels of any kind to integers\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1, # To monitor training at each epoch\n",
    "    \n",
    "    # handlers\n",
    "    on_epoch_finished = [EarlyStopping(patience=10, criterion='valid_accuracy', \n",
    "                                       criterion_smaller_is_better=False)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_vectorized_rescaled, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
