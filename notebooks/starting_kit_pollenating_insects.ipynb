{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science</a>\n",
    "## <a href=http://www.datascience-paris-saclay.fr/en/site/newsView/12>RAMP</a> on Pollenating Insects classification\n",
    "\n",
    "<i> Balázs Kégl (CNRS), Romain Julliard (Muséum National d'Histoire Naturelle), Alex Gramfort (LTCI), Mehdi Cherti (CNRS) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Pollenating insects play a fundamental role in the stability of ecosystems. An insect is said to be pollinator when it transports pollen from one flower to another, helping them to accomplish fertilization. The vast majority of plants pollenates using insects, and at the same time, these insects depend on plants for their survival. However, because of human intensified agrigulture, urbanisation and climate change, these species are threatened. 35% of human alimentation is based on plants pollenated by insects. Diversity of these insects is also important, the more diverse they are the best overall assistance is provided by these insects.\n",
    "\n",
    "The SPIPOLL (Suivi Photographique des Insectes POLLinisateurs) project proposes to study quantitatively pollenating insects in France. For this, they created a crowdsourcing platform where anyone can upload pictures of insects and identify their species through a series of questions. These data are then used by specialists for further analyses.\n",
    "\n",
    "Reference : http://www.spipoll.org/\n",
    "\n",
    "## Data\n",
    "\n",
    "In this RAMP, we propose a dataset of pictures of insects from different species gathered from the SPIPOLL project and labeled by specialists. The dataset contains a set of 20348 labeled pictures of insects, there are 18 different classes each one corresponding to a different insect specie. Each picture is a 64x64 colored image, which makes a total of $64 \\times 64 \\times 3=12288$ features per picture.\n",
    "\n",
    "## The prediction task\n",
    "\n",
    "The goal of this RAMP is to classify correctly the species of the insects. For each submission, you will have to provide a classifier, which will fit a training set and predict the classes (species) on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 20\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load(\"train_64x64.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = data['X'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look first at the distribution of of the pixel intensities for each color separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = dict(R=0, G=1, B=2)\n",
    "subsample = np.random.choice(np.arange(X.shape[0]), replace=False, size=500)\n",
    "plt.hist(X[subsample, :, :, colors[\"R\"]].flatten(), color=\"red\", normed=True)\n",
    "plt.title(\"Red color distribution\")\n",
    "plt.show()\n",
    "plt.hist(X[subsample, :, :, colors[\"G\"]].flatten(), color=\"green\", normed=True)\n",
    "plt.title(\"Green color distribution\")\n",
    "plt.show()\n",
    "plt.hist(X[subsample, :, :, colors[\"B\"]].flatten(), color=\"blue\", normed=True)\n",
    "plt.title(\"Blue color distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the distribution of the labels. The labels given are taxon ids, not strings, but we can convert them to strings to know for which species they refer to, we will see that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(y).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see for which species these taxon ids refer to.\n",
    "\n",
    "We first load <code>taxon_id_to_french_names</code> a file which contains\n",
    "the mapping between taxon ids and species names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = pd.read_table(\"taxon_id_to_french_names.txt\", sep=\"\\s{2,}\", \n",
    "                       names=[\"name\", \"taxon_id\"], \n",
    "                       index_col=\"taxon_id\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform the mapping to get labels of the examples but with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_names = pd.Series(y).map(labels[\"name\"].to_dict())\n",
    "y_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of examples per specie is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_names.groupby(y_names.values).size().sort(inplace=False, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_names.groupby(y_names.values).size().sort(inplace=False).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_rows = 4\n",
    "nb_cols = 4\n",
    "nb_elements = nb_rows * nb_cols\n",
    "class_id = 970\n",
    "\n",
    "print(\"Specie : {0}\".format(labels.loc[class_id]))\n",
    "\n",
    "X_given_class_id = X[y==class_id]\n",
    "\n",
    "subsample = np.random.choice(np.arange(X_given_class_id.shape[0]), replace=False, size=nb_elements)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = AxesGrid(fig, 111, # similar to subplot(141)\n",
    "                nrows_ncols = (nb_rows, nb_cols),\n",
    "                axes_pad = 0.05,\n",
    "                label_mode = \"1\",\n",
    ")\n",
    "for i, image_index in enumerate(subsample):\n",
    "    im = grid[i].imshow(X_given_class_id[i, :, :]/255.)\n",
    "    grid[i].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said earlier, the goal of this RAMP is to classify correctly the species of the insects. For each submission, you will have to provide a Classifier class, following [scikit-learn](scikit-learn.org) convention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by a simple **random forest** classifier, as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "class Classifier(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_vectorized = X.reshape((X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))    \n",
    "        self.clf = RandomForestClassifier(\n",
    "            n_estimators=10, max_features=2, max_leaf_nodes=5)\n",
    "        self.clf.fit(X_vectorized, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        X_vectorized = X.reshape((X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))    \n",
    "        return self.clf.predict(X_vectorized)\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        X_vectorized = X.reshape((X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))    \n",
    "        return self.clf.predict_proba(X_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unit_test(classifier, nb_iter=5):\n",
    "    test_size = 0.2\n",
    "    random_state = 15\n",
    "    cv = StratifiedShuffleSplit(y, nb_iter,\n",
    "                                test_size=test_size\n",
    ",\n",
    "                                random_state=random_state)\n",
    "    clf = classifier()\n",
    "    scores = cross_val_score(clf, X=X, y=y, scoring='accuracy', cv=cv)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(unit_test(Classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a vanilla **feedforward neural net**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    inp = Input(shape=(64 * 64 * 3,))\n",
    "    h1 = Dense(500, activation='relu')(inp)\n",
    "    h2 = Dense(500, activation='relu')(h1)\n",
    "    out = Dense(18, activation='softmax')(h2)\n",
    "    \n",
    "    model = Model(input=inp, output=out)\n",
    "    optimizer = RMSprop(lr=0.001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "        self.label_encoder = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.preprocess_X(X)\n",
    "        y = self.preprocess_y(y)\n",
    "        self.model.fit(X, y, verbose=1, validation_split=0.2, nb_epoch=10)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess_X(X)\n",
    "        y = self.model.predict_classes(X)\n",
    "        y = self.deprocess_y(y)\n",
    "        return y\n",
    "\n",
    "    def preprocess_X(self, X):\n",
    "        X = X.reshape((X.shape[0], X.shape[1] * X.shape[2] * X.shape[3])) # flatten images to vectors\n",
    "        X = X / 255.\n",
    "        return X\n",
    "    \n",
    "    def preprocess_y(self, y):\n",
    "        if self.label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.label_encoder.fit(y)\n",
    "        y = self.label_encoder.transform(y)\n",
    "        y = np_utils.to_categorical(y)\n",
    "        return y\n",
    "    \n",
    "    def deprocess_y(self, y):\n",
    "        return self.label_encoder.inverse_transform(y)\n",
    "            \n",
    "classifier = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On machines without GPUs this will take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(unit_test(Classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try a basic **convolutional neural net**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    inp = Input(shape=(3, 64, 64))\n",
    "    c1 = Convolution2D(16, 3, 3, activation='relu')(inp)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    c2 = Convolution2D(32, 3, 3, activation='relu')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    c3 = Convolution2D(32, 3, 3, activation='relu')(p2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    fc1 = Dense(200, activation='relu')(Flatten()(p3))\n",
    "    fc2 = Dense(200, activation='relu')(fc1)\n",
    "    out = Dense(18, activation='softmax')(fc2)\n",
    "\n",
    "    model = Model(input=inp, output=out)\n",
    "    optimizer = RMSprop(lr=0.001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "        self.label_encoder = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.preprocess_X(X)\n",
    "        y = self.preprocess_y(y)\n",
    "        self.model.fit(X, y, verbose=1, \n",
    "                       validation_split=0.2,\n",
    "                       callbacks=[EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')],\n",
    "                       nb_epoch=10)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess_X(X)\n",
    "        y = self.model.predict_classes(X)\n",
    "        y = self.deprocess_y(y)\n",
    "        return y\n",
    "\n",
    "    def preprocess_X(self, X):\n",
    "        X = X.transpose((0, 3, 1, 2)) # make color channel as second dimesion\n",
    "        X = X / 255.\n",
    "        return X\n",
    "    \n",
    "    def preprocess_y(self, y):\n",
    "        if self.label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.label_encoder.fit(y)\n",
    "        y = self.label_encoder.transform(y)\n",
    "        y = np_utils.to_categorical(y)\n",
    "        return y\n",
    "    \n",
    "    def deprocess_y(self, y):\n",
    "        return self.label_encoder.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't run the following cell at home. If the classical neural net was slow, this will never terminate unless you run it on a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(unit_test(Classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "For submitting your code, first create a github repo and enter its public address (https://...) at the submission site. Place your to file <code>classifier.py</code> in the git repo, and then run the following sequence.\n",
    "\n",
    "<code>\n",
    "git add classifier.py\n",
    "git commit -m \"my commit log\"\n",
    "git tag model_description\n",
    "git push origin master --tags\n",
    "</code>\n",
    "\n",
    "We will fetch your submission. At this point it will appear in the \"New models\" table. Once it is trained, it will either be added to the leaderboards, or it will appear in the \"Failed models\" table. Clicking on “error” will bring you to the error that python threw.\n",
    "\n",
    "### Deleting failed models\n",
    "\n",
    "You cannot delete models once they appear in the leaderboard. However, you can delete failed models by executing the following sequence:\n",
    "\n",
    "<code>\n",
    "git tag -d model_description\n",
    "git push origin :refs/tags/model_description\n",
    "</code>\n",
    "\n",
    "The first command deletes your local tag and the second command deletes the remote tag. When we fetch next time, the model will disappear from the table. You can then reuse the tag to resubmit another model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
