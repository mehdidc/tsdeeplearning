{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K20Xm (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "from lasagne import layers, nonlinearities\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, net):\n",
    "        #self.X = X\n",
    "        #self.y = y\n",
    "        self.net = net \n",
    "\n",
    "    def preprocess(self, X):\n",
    "        X = (X / 255.)\n",
    "        X = X.astype(np.float32)\n",
    "        X = X.transpose((0, 3, 1, 2))\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.preprocess(X)\n",
    "        self.net.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        return self.net.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        return self.net.predict_proba(X)\n",
    "    \n",
    "\n",
    "def unit_test(X, y, clf, nb_iter=5):\n",
    "    test_size = 0.2\n",
    "    random_state = 15\n",
    "    cv = StratifiedShuffleSplit(y, nb_iter,\n",
    "                                test_size=test_size,\n",
    "                                random_state=random_state)\n",
    "    scores = cross_val_score(clf, X=X, y=y, scoring='accuracy', cv=cv)\n",
    "    return scores\n",
    "\n",
    "def unit_test2(X, y, clf, nb_iter=5):  \n",
    "    test_size = 0.2\n",
    "    random_state = 15\n",
    "    cv = StratifiedShuffleSplit(y, nb_iter,\n",
    "                                test_size=test_size,\n",
    "                                random_state=random_state)\n",
    "    #scores = cross_val_score(clf, X=X, y=y, scoring='accuracy', cv=cv)\n",
    "    scores = []\n",
    "    for train, test in cv:\n",
    "        clf.fit(X[train], y[train])\n",
    "        acc = (clf.predict(X[test])==y[test]).mean()\n",
    "        scores.append(acc)\n",
    "    return scores\n",
    "\n",
    "data = np.load(\"train_64x64.npz\")\n",
    "\n",
    "X, y = data['X'], data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make sure we can overfit the training set, by using a CNN (Convolutional Neural Network) big enough to reduce the training error close to 0, without any regularization (e.g. dropout, L2, etc.).In this exploratory phase we want to reduce the training time as much as possible, while still leaving enough epochs of training to see the training loss going close to 0. In this spirit, we will set the number of cross-validation iterations to 1 (instead of the default 5) and the maximum number of training epochs to 30 (we could also increase the maximum number of training epochs even more and stop the training manually if we thought we already had enough evidence of overfitting and training was taking too long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 3496370 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ---------\n",
      "  0  input    3x64x64\n",
      "  1  conv1    64x62x62\n",
      "  2  pool1    64x31x31\n",
      "  3  conv2    128x30x30\n",
      "  4  pool2    128x15x15\n",
      "  5  conv3    128x14x14\n",
      "  6  pool3    128x7x7\n",
      "  7  hidden4  500\n",
      "  8  hidden5  500\n",
      "  9  output   18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.48588\u001b[0m       \u001b[32m2.45851\u001b[0m      1.01113      0.28275  8.67s\n",
      "      2       \u001b[36m2.42201\u001b[0m       \u001b[32m2.38081\u001b[0m      1.01731      0.30981  8.63s\n",
      "      3       \u001b[36m2.32502\u001b[0m       \u001b[32m2.27260\u001b[0m      1.02307      0.34622  8.62s\n",
      "      4       \u001b[36m2.21311\u001b[0m       \u001b[32m2.19140\u001b[0m      1.00991      0.36246  8.62s\n",
      "      5       \u001b[36m2.13006\u001b[0m       \u001b[32m2.12441\u001b[0m      1.00266      0.37809  8.62s\n",
      "      6       \u001b[36m2.04799\u001b[0m       \u001b[32m2.07170\u001b[0m      0.98856      0.38470  8.62s\n",
      "      7       \u001b[36m1.96003\u001b[0m       \u001b[32m2.01158\u001b[0m      0.97437      0.40004  8.61s\n",
      "      8       \u001b[36m1.86655\u001b[0m       \u001b[32m1.99455\u001b[0m      0.93583      0.40698  8.61s\n",
      "      9       \u001b[36m1.78396\u001b[0m       \u001b[32m1.98735\u001b[0m      0.89766      0.40791  8.61s\n",
      "     10       \u001b[36m1.68080\u001b[0m       2.02931      0.82826      0.39708  8.61s\n",
      "     11       \u001b[36m1.57648\u001b[0m       2.12592      0.74155      0.37786  8.61s\n",
      "     12       \u001b[36m1.48515\u001b[0m       2.13260      0.69640      0.40128  8.61s\n",
      "     13       \u001b[36m1.35155\u001b[0m       2.15147      0.62820      0.40074  8.61s\n",
      "     14       \u001b[36m1.17801\u001b[0m       2.32213      0.50730      0.40039  8.61s\n",
      "     15       \u001b[36m1.15985\u001b[0m       2.51177      0.46176      0.31296  8.61s\n",
      "     16       \u001b[36m0.96792\u001b[0m       2.66594      0.36307      0.35203  8.62s\n",
      "     17       \u001b[36m0.80291\u001b[0m       3.02490      0.26543      0.29076  8.62s\n",
      "     18       \u001b[36m0.70421\u001b[0m       3.45893      0.20359      0.31830  8.61s\n",
      "     19       \u001b[36m0.60671\u001b[0m       4.15097      0.14616      0.29397  8.61s\n",
      "     20       \u001b[36m0.48704\u001b[0m       3.94735      0.12338      0.29037  8.62s\n",
      "     21       \u001b[36m0.42943\u001b[0m       4.02594      0.10667      0.32764  8.61s\n",
      "     22       \u001b[36m0.35746\u001b[0m       4.20098      0.08509      0.32494  8.62s\n",
      "     23       \u001b[36m0.33663\u001b[0m       4.51351      0.07458      0.30003  8.61s\n",
      "     24       \u001b[36m0.28839\u001b[0m       4.90606      0.05878      0.32945  8.62s\n",
      "     25       \u001b[36m0.25750\u001b[0m       5.14794      0.05002      0.34538  8.62s\n",
      "     26       \u001b[36m0.23820\u001b[0m       5.12173      0.04651      0.32675  8.61s\n",
      "     27       \u001b[36m0.20955\u001b[0m       5.16965      0.04054      0.33665  8.62s\n",
      "     28       \u001b[36m0.17877\u001b[0m       5.37227      0.03328      0.35918  8.61s\n",
      "     29       \u001b[36m0.16028\u001b[0m       5.26030      0.03047      0.32884  8.62s\n",
      "     30       \u001b[36m0.13506\u001b[0m       5.60330      0.02410      0.33491  8.61s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34390363815142577]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameters = dict(conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "            conv2_num_filters=128, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "            conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "            hidden4_num_units=500, hidden5_num_units=500,\n",
    "            output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "            update_learning_rate=0.01,\n",
    "            update_momentum=0.9,\n",
    "            max_epochs=30,\n",
    "        )\n",
    "\n",
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=1,\n",
    "        **hyper_parameters\n",
    "    )\n",
    "\n",
    "data = np.load(\"train_64x64.npz\")\n",
    "\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "#X = (X / 255.)\n",
    "#X = X.astype(np.float32)\n",
    "#X = X.transpose((0, 3, 1, 2))\n",
    "\n",
    "#how can this take longer than calling unit_test?????\n",
    "#net.fit(X, y)\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that while the training loss keeps going down, after a certain epoch the validation loss keeps increasing and the validation accuracy fluctuates; this is evidence of overfitting. \n",
    "Our CNN seems big enough to be able to memorize the training set, while allowing for decent training time. We could now try to deal with the overfitting; a good, first choice method could be adding dropout layers, especially after the fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 3496370 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     3x64x64\n",
      "  1  conv1     64x62x62\n",
      "  2  pool1     64x31x31\n",
      "  3  conv2     128x30x30\n",
      "  4  pool2     128x15x15\n",
      "  5  conv3     128x14x14\n",
      "  6  pool3     128x7x7\n",
      "  7  hidden4   500\n",
      "  8  dropout4  500\n",
      "  9  hidden5   500\n",
      " 10  dropout5  500\n",
      " 11  output    18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.52702\u001b[0m       \u001b[32m2.47076\u001b[0m      1.02277      0.28275  8.69s\n",
      "      2       \u001b[36m2.46551\u001b[0m       \u001b[32m2.45832\u001b[0m      1.00293      0.28275  8.61s\n",
      "      3       \u001b[36m2.45060\u001b[0m       \u001b[32m2.44256\u001b[0m      1.00329      0.28275  8.62s\n",
      "      4       \u001b[36m2.41406\u001b[0m       \u001b[32m2.37222\u001b[0m      1.01764      0.32695  8.61s\n",
      "      5       \u001b[36m2.33618\u001b[0m       \u001b[32m2.27582\u001b[0m      1.02652      0.35883  8.62s\n",
      "      6       \u001b[36m2.26065\u001b[0m       \u001b[32m2.21441\u001b[0m      1.02088      0.37145  8.61s\n",
      "      7       \u001b[36m2.22089\u001b[0m       \u001b[32m2.18130\u001b[0m      1.01815      0.37416  8.60s\n",
      "      8       \u001b[36m2.19307\u001b[0m       \u001b[32m2.15521\u001b[0m      1.01757      0.37867  8.60s\n",
      "      9       \u001b[36m2.17212\u001b[0m       \u001b[32m2.12921\u001b[0m      1.02015      0.38168  8.60s\n",
      "     10       \u001b[36m2.14491\u001b[0m       \u001b[32m2.09893\u001b[0m      1.02191      0.38588  8.61s\n",
      "     11       \u001b[36m2.11962\u001b[0m       \u001b[32m2.07461\u001b[0m      1.02169      0.38588  8.60s\n",
      "     12       \u001b[36m2.08580\u001b[0m       \u001b[32m2.01793\u001b[0m      1.03363      0.39551  8.60s\n",
      "     13       \u001b[36m2.02675\u001b[0m       \u001b[32m1.94839\u001b[0m      1.04022      0.41565  8.60s\n",
      "     14       \u001b[36m1.96505\u001b[0m       \u001b[32m1.89583\u001b[0m      1.03651      0.42588  8.60s\n",
      "     15       \u001b[36m1.92151\u001b[0m       \u001b[32m1.86105\u001b[0m      1.03249      0.43880  8.61s\n",
      "     16       \u001b[36m1.88663\u001b[0m       \u001b[32m1.83773\u001b[0m      1.02661      0.43881  8.61s\n",
      "     17       \u001b[36m1.86970\u001b[0m       1.84751      1.01201      0.44723  8.61s\n",
      "     18       \u001b[36m1.86748\u001b[0m       \u001b[32m1.83389\u001b[0m      1.01832      0.44423  8.61s\n",
      "     19       \u001b[36m1.84188\u001b[0m       \u001b[32m1.82650\u001b[0m      1.00842      0.44633  8.61s\n",
      "     20       \u001b[36m1.82215\u001b[0m       \u001b[32m1.81292\u001b[0m      1.00510      0.44994  8.61s\n",
      "     21       \u001b[36m1.78224\u001b[0m       \u001b[32m1.78429\u001b[0m      0.99885      0.45685  8.61s\n",
      "     22       \u001b[36m1.73570\u001b[0m       \u001b[32m1.74552\u001b[0m      0.99437      0.47281  8.61s\n",
      "     23       \u001b[36m1.69900\u001b[0m       \u001b[32m1.72464\u001b[0m      0.98513      0.48062  8.61s\n",
      "     24       \u001b[36m1.64879\u001b[0m       \u001b[32m1.70138\u001b[0m      0.96909      0.48664  8.60s\n",
      "     25       \u001b[36m1.60459\u001b[0m       \u001b[32m1.68223\u001b[0m      0.95385      0.49146  8.60s\n",
      "     26       \u001b[36m1.54086\u001b[0m       \u001b[32m1.65150\u001b[0m      0.93301      0.49808  8.61s\n",
      "     27       \u001b[36m1.50485\u001b[0m       1.67712      0.89728      0.49445  8.61s\n",
      "     28       \u001b[36m1.46469\u001b[0m       1.65792      0.88345      0.49505  8.61s\n",
      "     29       \u001b[36m1.43821\u001b[0m       \u001b[32m1.64989\u001b[0m      0.87170      0.50499  8.61s\n",
      "     30       \u001b[36m1.40711\u001b[0m       \u001b[32m1.63903\u001b[0m      0.85851      0.50770  8.61s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.51892822025565388]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('dropout4', layers.DropoutLayer),  # !\n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),  # !\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=1,\n",
    "        conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "            conv2_num_filters=128, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "            conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "            hidden4_num_units=500, \n",
    "            dropout4_p=0.5,  # !\n",
    "            hidden5_num_units=500,\n",
    "            dropout5_p=0.5,  # !\n",
    "            output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "            update_learning_rate=0.01,\n",
    "            update_momentum=0.9,\n",
    "            max_epochs=30,\n",
    "    )\n",
    "\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: MSR initialization, learning rate annealing, Adam; convolution + max-pooling illustrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the CNN is now well-enough regularized so as to no longer overfit, and after 30 epochs of training the training loss hasn't converged and the validation accuracy keeps improving. We can thus increase the maximum number of training epochs, in the hope that this will lead to even better validation accuracy. To stop the training procedure automatically (without having to check whether the validation accuracy is still improving after each couple of epochs and then stop the procedure manually), we can use a technique called early stopping. We will also increase the number of maximum training epochs to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 3496370 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     3x64x64\n",
      "  1  conv1     64x62x62\n",
      "  2  pool1     64x31x31\n",
      "  3  conv2     128x30x30\n",
      "  4  pool2     128x15x15\n",
      "  5  conv3     128x14x14\n",
      "  6  pool3     128x7x7\n",
      "  7  hidden4   500\n",
      "  8  dropout4  500\n",
      "  9  hidden5   500\n",
      " 10  dropout5  500\n",
      " 11  output    18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.51599\u001b[0m       \u001b[32m2.47018\u001b[0m      1.01855      0.28275  8.68s\n",
      "      2       \u001b[36m2.46085\u001b[0m       \u001b[32m2.45187\u001b[0m      1.00366      0.28275  8.88s\n",
      "      3       \u001b[36m2.43908\u001b[0m       \u001b[32m2.42682\u001b[0m      1.00505      0.28275  8.92s\n",
      "      4       \u001b[36m2.40050\u001b[0m       \u001b[32m2.36129\u001b[0m      1.01661      0.33057  8.89s\n",
      "      5       \u001b[36m2.32766\u001b[0m       \u001b[32m2.27343\u001b[0m      1.02385      0.35882  8.64s\n",
      "      6       \u001b[36m2.26093\u001b[0m       \u001b[32m2.21437\u001b[0m      1.02103      0.37025  8.63s\n",
      "      7       \u001b[36m2.22364\u001b[0m       \u001b[32m2.18167\u001b[0m      1.01924      0.37417  8.63s\n",
      "      8       \u001b[36m2.19250\u001b[0m       \u001b[32m2.15089\u001b[0m      1.01934      0.37386  8.64s\n",
      "      9       \u001b[36m2.15845\u001b[0m       \u001b[32m2.11195\u001b[0m      1.02202      0.37837  8.64s\n",
      "     10       \u001b[36m2.12039\u001b[0m       \u001b[32m2.06563\u001b[0m      1.02651      0.38558  8.68s\n",
      "     11       \u001b[36m2.07404\u001b[0m       \u001b[32m2.00869\u001b[0m      1.03253      0.40151  8.63s\n"
     ]
    }
   ],
   "source": [
    "# code source: \n",
    "# http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n",
    "# adapted to use the validation accuracy, rather than the validation loss\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=20):\n",
    "        self.patience = patience\n",
    "        self.best_valid = - np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_accuracy']\n",
    "        #print(train_history[-1])\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid > self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best validation accuracy was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()\n",
    "            \n",
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('dropout4', layers.DropoutLayer),  \n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),  \n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=1,\n",
    "        conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "        conv2_num_filters=128, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "        conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "        hidden4_num_units=500, \n",
    "        dropout4_p=0.5,  \n",
    "        hidden5_num_units=500,\n",
    "        dropout5_p=0.5,  \n",
    "        output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "        max_epochs=100,   # !\n",
    "        on_epoch_finished=[\n",
    "            EarlyStopping(patience=20),\n",
    "            ],    # !\n",
    "    )\n",
    "\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 3496370 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     3x64x64\n",
      "  1  conv1     64x62x62\n",
      "  2  pool1     64x31x31\n",
      "  3  conv2     128x30x30\n",
      "  4  pool2     128x15x15\n",
      "  5  conv3     128x14x14\n",
      "  6  pool3     128x7x7\n",
      "  7  hidden4   500\n",
      "  8  dropout4  500\n",
      "  9  hidden5   500\n",
      " 10  dropout5  500\n",
      " 11  output    18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.50736\u001b[0m       \u001b[32m2.46144\u001b[0m      1.01865      0.28275  8.79s\n",
      "      2       \u001b[36m2.45095\u001b[0m       \u001b[32m2.43589\u001b[0m      1.00618      0.28275  8.77s\n",
      "      3       \u001b[36m2.40795\u001b[0m       \u001b[32m2.35649\u001b[0m      1.02184      0.33207  8.71s\n",
      "      4       \u001b[36m2.31090\u001b[0m       \u001b[32m2.24590\u001b[0m      1.02894      0.35852  8.66s\n",
      "      5       \u001b[36m2.22343\u001b[0m       \u001b[32m2.16668\u001b[0m      1.02619      0.37235  8.65s\n",
      "      6       \u001b[36m2.15814\u001b[0m       \u001b[32m2.09310\u001b[0m      1.03107      0.38228  8.66s\n",
      "      7       \u001b[36m2.09454\u001b[0m       \u001b[32m2.02755\u001b[0m      1.03304      0.40362  8.84s\n",
      "      8       \u001b[36m2.03541\u001b[0m       \u001b[32m1.96700\u001b[0m      1.03478      0.41083  8.97s\n",
      "      9       \u001b[36m1.97693\u001b[0m       \u001b[32m1.93034\u001b[0m      1.02413      0.41956  8.97s\n",
      "     10       \u001b[36m1.94951\u001b[0m       \u001b[32m1.89995\u001b[0m      1.02608      0.42979  8.96s\n",
      "     11       \u001b[36m1.88849\u001b[0m       \u001b[32m1.83319\u001b[0m      1.03016      0.44515  8.94s\n",
      "     12       \u001b[36m1.82285\u001b[0m       \u001b[32m1.78031\u001b[0m      1.02389      0.45387  8.89s\n",
      "     13       \u001b[36m1.77807\u001b[0m       \u001b[32m1.75136\u001b[0m      1.01525      0.46919  8.69s\n",
      "     14       \u001b[36m1.72805\u001b[0m       \u001b[32m1.72631\u001b[0m      1.00101      0.47010  8.97s\n",
      "     15       \u001b[36m1.68170\u001b[0m       \u001b[32m1.68873\u001b[0m      0.99584      0.48484  8.89s\n",
      "     16       \u001b[36m1.65279\u001b[0m       \u001b[32m1.68461\u001b[0m      0.98111      0.48603  8.78s\n",
      "     17       \u001b[36m1.61418\u001b[0m       1.69142      0.95433      0.48724  8.87s\n",
      "     18       \u001b[36m1.57178\u001b[0m       \u001b[32m1.66479\u001b[0m      0.94413      0.48966  8.96s\n",
      "     19       \u001b[36m1.53518\u001b[0m       \u001b[32m1.65092\u001b[0m      0.92989      0.49901  8.83s\n",
      "     20       \u001b[36m1.49365\u001b[0m       \u001b[32m1.64777\u001b[0m      0.90647      0.49810  8.86s\n",
      "     21       \u001b[36m1.45783\u001b[0m       1.66871      0.87363      0.49415  8.77s\n",
      "     22       \u001b[36m1.40324\u001b[0m       1.66052      0.84506      0.50566  8.66s\n",
      "     23       \u001b[36m1.35978\u001b[0m       1.67079      0.81385      0.49963  8.83s\n",
      "     24       \u001b[36m1.31355\u001b[0m       1.69946      0.77292      0.49752  8.79s\n",
      "     25       \u001b[36m1.25690\u001b[0m       1.70731      0.73619      0.49601  8.66s\n",
      "     26       \u001b[36m1.19129\u001b[0m       1.75690      0.67806      0.50322  8.66s\n",
      "     27       \u001b[36m1.16222\u001b[0m       1.79251      0.64837      0.49204  8.77s\n",
      "     28       \u001b[36m1.09134\u001b[0m       1.88099      0.58019      0.49391  8.91s\n",
      "     29       \u001b[36m1.04048\u001b[0m       1.90684      0.54566      0.48996  8.87s\n",
      "     30       \u001b[36m0.96326\u001b[0m       1.96780      0.48951      0.47855  8.66s\n",
      "     31       \u001b[36m0.91477\u001b[0m       2.09579      0.43648      0.46743  8.66s\n",
      "     32       \u001b[36m0.85920\u001b[0m       2.20106      0.39036      0.46263  8.69s\n",
      "     33       \u001b[36m0.82230\u001b[0m       2.28618      0.35969      0.45541  8.83s\n",
      "     34       \u001b[36m0.76858\u001b[0m       2.39526      0.32087      0.45750  8.73s\n",
      "     35       \u001b[36m0.72802\u001b[0m       2.35914      0.30860      0.45810  8.91s\n",
      "     36       \u001b[36m0.70413\u001b[0m       2.44998      0.28740      0.46169  8.94s\n",
      "     37       \u001b[36m0.64345\u001b[0m       2.63024      0.24464      0.44191  8.77s\n",
      "     38       \u001b[36m0.64224\u001b[0m       2.62588      0.24458      0.44456  8.71s\n",
      "     39       \u001b[36m0.61374\u001b[0m       2.72344      0.22535      0.43290  8.66s\n",
      "     40       \u001b[36m0.57978\u001b[0m       2.84309      0.20393      0.44188  8.67s\n",
      "     41       \u001b[36m0.55513\u001b[0m       3.01213      0.18430      0.43253  8.92s\n",
      "     42       \u001b[36m0.54436\u001b[0m       3.00781      0.18098      0.43523  8.69s\n",
      "Early stopping.\n",
      "Best validation accuracy was 0.505657 at epoch 22.\n",
      "Loaded parameters to layer 'conv1' (shape 64x3x3x3).\n",
      "Loaded parameters to layer 'conv1' (shape 64).\n",
      "Loaded parameters to layer 'conv2' (shape 128x64x2x2).\n",
      "Loaded parameters to layer 'conv2' (shape 128).\n",
      "Loaded parameters to layer 'conv3' (shape 128x128x2x2).\n",
      "Loaded parameters to layer 'conv3' (shape 128).\n",
      "Loaded parameters to layer 'hidden4' (shape 6272x500).\n",
      "Loaded parameters to layer 'hidden4' (shape 500).\n",
      "Loaded parameters to layer 'hidden5' (shape 500x500).\n",
      "Loaded parameters to layer 'hidden5' (shape 500).\n",
      "Loaded parameters to layer 'output' (shape 500x18).\n",
      "Loaded parameters to layer 'output' (shape 18).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.50319567354965589]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=20):\n",
    "        self.patience = patience\n",
    "        self.best_valid = - np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_accuracy']\n",
    "        #print(train_history[-1])\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid > self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best validation accuracy was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()\n",
    "            \n",
    "\n",
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('dropout4', layers.DropoutLayer),  \n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),  \n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=1,\n",
    "        conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "        #conv1_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        conv2_num_filters=128, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "        #conv2_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2), \n",
    "        #conv3_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        hidden4_num_units=500, hidden4_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout4_p=0.5,  \n",
    "        hidden5_num_units=500, hidden5_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout5_p=0.5,  \n",
    "        output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "        max_epochs=100, \n",
    "        on_epoch_finished=[\n",
    "            EarlyStopping(patience=20),\n",
    "            ], \n",
    "    )\n",
    "\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the train / validation loss ratio still seems to become very small after a certain number of epochs. We can try to regularize the CNN even more, by adding dropout between the CNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 3496370 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     3x64x64\n",
      "  1  conv1     64x62x62\n",
      "  2  pool1     64x31x31\n",
      "  3  dropout1  64x31x31\n",
      "  4  conv2     128x30x30\n",
      "  5  pool2     128x15x15\n",
      "  6  dropout2  128x15x15\n",
      "  7  conv3     128x14x14\n",
      "  8  pool3     128x7x7\n",
      "  9  dropout3  128x7x7\n",
      " 10  hidden4   500\n",
      " 11  dropout4  500\n",
      " 12  hidden5   500\n",
      " 13  dropout5  500\n",
      " 14  output    18\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m2.50717\u001b[0m       \u001b[32m2.53538\u001b[0m      0.98888      0.28275  9.17s\n",
      "      2       \u001b[36m2.46273\u001b[0m       \u001b[32m2.51567\u001b[0m      0.97895      0.28275  9.11s\n",
      "      3       \u001b[36m2.45210\u001b[0m       \u001b[32m2.49026\u001b[0m      0.98467      0.28275  9.12s\n",
      "      4       \u001b[36m2.41018\u001b[0m       \u001b[32m2.43447\u001b[0m      0.99002      0.28577  9.18s\n",
      "      5       \u001b[36m2.32680\u001b[0m       \u001b[32m2.36617\u001b[0m      0.98336      0.32425  9.21s\n",
      "      6       \u001b[36m2.28683\u001b[0m       \u001b[32m2.32572\u001b[0m      0.98328      0.34409  9.38s\n",
      "      7       \u001b[36m2.26444\u001b[0m       \u001b[32m2.31572\u001b[0m      0.97786      0.34619  9.15s\n",
      "      8       \u001b[36m2.24789\u001b[0m       \u001b[32m2.30450\u001b[0m      0.97543      0.34890  9.12s\n",
      "      9       \u001b[36m2.23599\u001b[0m       2.30830      0.96867      0.34920  9.28s\n",
      "     10       \u001b[36m2.22743\u001b[0m       2.31097      0.96385      0.34739  9.43s\n",
      "     11       \u001b[36m2.21966\u001b[0m       2.31587      0.95846      0.34619  9.15s\n",
      "     12       \u001b[36m2.21802\u001b[0m       2.32027      0.95593      0.34048  9.12s\n",
      "     13       \u001b[36m2.20661\u001b[0m       2.31763      0.95210      0.34289  9.31s\n",
      "     14       \u001b[36m2.19408\u001b[0m       \u001b[32m2.29401\u001b[0m      0.95644      0.34589  9.27s\n",
      "     15       \u001b[36m2.18963\u001b[0m       \u001b[32m2.28941\u001b[0m      0.95642      0.34470  9.12s\n",
      "     16       \u001b[36m2.17741\u001b[0m       \u001b[32m2.26254\u001b[0m      0.96238      0.34981  9.31s\n",
      "     17       \u001b[36m2.16561\u001b[0m       \u001b[32m2.25013\u001b[0m      0.96244      0.35642  9.43s\n",
      "     18       \u001b[36m2.15504\u001b[0m       \u001b[32m2.24599\u001b[0m      0.95950      0.35462  9.28s\n",
      "     19       \u001b[36m2.14658\u001b[0m       \u001b[32m2.23598\u001b[0m      0.96002      0.35462  9.43s\n",
      "     20       \u001b[36m2.14347\u001b[0m       2.24714      0.95386      0.35161  9.43s\n",
      "     21       \u001b[36m2.13274\u001b[0m       \u001b[32m2.23273\u001b[0m      0.95521      0.35552  9.35s\n",
      "     22       \u001b[36m2.12605\u001b[0m       2.24435      0.94729      0.34920  9.20s\n",
      "     23       \u001b[36m2.12488\u001b[0m       2.24828      0.94512      0.34920  9.13s\n",
      "     24       \u001b[36m2.11358\u001b[0m       2.25470      0.93741      0.34529  9.21s\n",
      "     25       \u001b[36m2.10799\u001b[0m       2.25041      0.93671      0.34738  9.43s\n",
      "     26       \u001b[36m2.10677\u001b[0m       2.23648      0.94200      0.35130  9.44s\n",
      "     27       \u001b[36m2.09396\u001b[0m       2.23958      0.93498      0.34920  9.22s\n",
      "     28       \u001b[36m2.08665\u001b[0m       \u001b[32m2.22739\u001b[0m      0.93681      0.34739  9.13s\n",
      "     29       \u001b[36m2.07596\u001b[0m       2.24257      0.92571      0.34649  9.14s\n",
      "     30       \u001b[36m2.07046\u001b[0m       2.22771      0.92941      0.34679  9.13s\n",
      "     31       2.07247       2.23622      0.92677      0.34258  9.13s\n",
      "     32       \u001b[36m2.05593\u001b[0m       \u001b[32m2.22127\u001b[0m      0.92557      0.34438  9.13s\n",
      "     33       \u001b[36m2.05260\u001b[0m       2.24174      0.91563      0.34198  9.13s\n",
      "     34       \u001b[36m2.04368\u001b[0m       \u001b[32m2.21550\u001b[0m      0.92245      0.34981  9.13s\n",
      "     35       \u001b[36m2.04192\u001b[0m       \u001b[32m2.20313\u001b[0m      0.92683      0.35130  9.13s\n",
      "     36       \u001b[36m2.03206\u001b[0m       2.20400      0.92199      0.34558  9.13s\n",
      "     37       \u001b[36m2.02270\u001b[0m       \u001b[32m2.19841\u001b[0m      0.92007      0.34558  9.15s\n",
      "Early stopping.\n",
      "Best validation accuracy was 0.356418 at epoch 17.\n",
      "Loaded parameters to layer 'conv1' (shape 64x3x3x3).\n",
      "Loaded parameters to layer 'conv1' (shape 64).\n",
      "Loaded parameters to layer 'conv2' (shape 128x64x2x2).\n",
      "Loaded parameters to layer 'conv2' (shape 128).\n",
      "Loaded parameters to layer 'conv3' (shape 128x128x2x2).\n",
      "Loaded parameters to layer 'conv3' (shape 128).\n",
      "Loaded parameters to layer 'hidden4' (shape 6272x500).\n",
      "Loaded parameters to layer 'hidden4' (shape 500).\n",
      "Loaded parameters to layer 'hidden5' (shape 500x500).\n",
      "Loaded parameters to layer 'hidden5' (shape 500).\n",
      "Loaded parameters to layer 'output' (shape 500x18).\n",
      "Loaded parameters to layer 'output' (shape 18).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36332350049164208]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),  # !  \n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('dropout2', layers.DropoutLayer),   # ! \n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('dropout3', layers.DropoutLayer),   # ! \n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('dropout4', layers.DropoutLayer),  \n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),  \n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=1,\n",
    "        conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "        #conv1_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout1_p=0.5, # !  \n",
    "        conv2_num_filters=128, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "        #conv2_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout2_p=0.5, # ! \n",
    "        conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2), \n",
    "        #conv3_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout3_p=0.5, # !\n",
    "        hidden4_num_units=500, hidden4_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout4_p=0.5,  \n",
    "        hidden5_num_units=500, hidden5_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout5_p=0.5,  \n",
    "        output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "        max_epochs=100, \n",
    "        on_epoch_finished=[\n",
    "            EarlyStopping(patience=20),\n",
    "            ], \n",
    "    )\n",
    "\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are clearly underfitting. While the fully connected part of the network is probably expressive enough, we can try to make the convolutional more expressive, so that it extracts better features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "net = NeuralNet(\n",
    "        layers=[\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),  # !  \n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('dropout2', layers.DropoutLayer),   # ! \n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('pool3', layers.MaxPool2DLayer),\n",
    "            ('dropout3', layers.DropoutLayer),   # ! \n",
    "            #('conv4', layers.Conv2DLayer),\n",
    "            #('pool4', layers.MaxPool2DLayer),\n",
    "            #('dropout4', layers.DropoutLayer),  \n",
    "            ('hidden5', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer), \n",
    "            ('hidden6', layers.DenseLayer),\n",
    "            ('dropout6', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "        input_shape=(None, 3, 64, 64),\n",
    "        use_label_encoder=True,\n",
    "        verbose=2,\n",
    "        conv1_num_filters=64, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "        #conv1_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout1_p=0.5, # !  \n",
    "        conv2_num_filters=128, conv2_filter_size=(3, 3), pool2_pool_size=(2, 2),\n",
    "        #conv2_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout2_p=0.5, # ! \n",
    "        conv3_num_filters=256, conv3_filter_size=(3, 3), pool3_pool_size=(2, 2), \n",
    "        #conv3_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        dropout3_p=0.5, # !\n",
    "        #conv4_num_filters=512, conv4_filter_size=(3, 3), pool4_pool_size=(2, 2), \n",
    "        #conv4_nonlinearity = nonlinearities.very_leaky_rectify,    # !\n",
    "        #dropout4_p=0.5, # ! \n",
    "        hidden5_num_units=500, hidden5_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout5_p=0.5,\n",
    "        hidden6_num_units=500, hidden6_nonlinearity = nonlinearities.very_leaky_rectify, # !\n",
    "        dropout6_p=0.5, \n",
    "        output_num_units=18, output_nonlinearity=nonlinearities.softmax,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "        max_epochs=100, \n",
    "        on_epoch_finished=[\n",
    "            EarlyStopping(patience=20),\n",
    "            ], \n",
    "    )\n",
    "\n",
    "clf = Classifier(net)\n",
    "\n",
    "unit_test2(X, y, clf, nb_iter=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
